{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: using JLD.@load in module Main conflicts with an existing identifier.\n"
     ]
    }
   ],
   "source": [
    "using BSON: @load\n",
    "using Flux\n",
    "using Flux.Optimise\n",
    "using Flux.Optimise: update!\n",
    "using Flux.Data: DataLoader\n",
    "using ImageFiltering\n",
    "using Images\n",
    "using ImageIO\n",
    "using MLDatasets: FashionMNIST\n",
    "using LinearAlgebra\n",
    "using MLDatasets\n",
    "using Plots\n",
    "using Zygote\n",
    "using FFTW\n",
    "using Distributions\n",
    "using SparseArrays\n",
    "using JLD\n",
    "using StatsBase\n",
    "using LaTeXStrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sample_fourier (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function sample_fourier(m, n)\n",
    "\n",
    "    F = dct(diagm(ones(n)),2)\n",
    "    index = zeros(m)\n",
    "    StatsBase.self_avoid_sample!(Vector(1:1:n),index)\n",
    "    return F[Int.(index),:]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $A_d$ be a $n\\times k$ matrix and $A$ be a $n\\times n$ unitary matrix.  The incoherence of the subspace $\\textit{Range}(A_d)$ with respect to the unitary matrix $A$ equals\n",
    "$$ \\sup_{x\\in\\mathcal{R}(A_d)\\cap \\mathcal{S}^{n-1}} \\|A x\\|_\\infty = \\max_{i \\in [n]}\\left\\{\\sup_{u\\in\\mathbb{R}^{k}} \\langle a_i, A_d u\\rangle \\text{ s.t. } \\|A_du\\|_2 = 1 \\right\\}$$\n",
    "where $a_i$ is the $i$-th row of $A$. Consider a (thin)-QR decompition of $A_d = QR$. Then,\n",
    "$$\\sup_{u\\in\\mathbb{R}^{k}} \\langle a_i, A_d u\\rangle \\text{ s.t. } \\|A_du\\|_2 = 1 \\Leftrightarrow  \\sup_{u\\in\\mathbb{R}^{k}} \\langle Q^\\top a_i, R u\\rangle \\text{ s.t. } \\|Ru\\|_2 = 1.$$\n",
    "Consider a change of variable of $u = R^{-1} v$, for some $v \\in \\mathbb{R}^k$. It is easy to see that this supremum value is $\\|Q^\\top a_i\\|_2$. Thus,\n",
    "$$ \\sup_{x\\in\\mathcal{R}(A_d)\\cap \\mathcal{S}^{n-1}} \\|A x\\|_\\infty = \\max_{i \\in [n]} \\|Q^\\top a_i\\|_2.$$\n",
    "\n",
    "\n",
    "We note that $\\sup_{x\\in\\mathcal{R}(A_d)\\cap \\mathcal{S}^{n-1}} \\|A x\\|_\\infty$ only provides an upper bound to the incoherence of the GNN w.r.t $A$ given by\n",
    "$$ \\sup_{x\\in\\mathcal{R}(G)\\cap \\mathcal{S}^{n-1}}\\|A x\\|_\\infty.$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subspace_incoherence (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function subspace_incoherence(F, A)\n",
    "    m, _ = size(A)\n",
    "    Q = Matrix(qr(A).Q)\n",
    "    temp = Q'*F'\n",
    "    return maximum(sqrt.(sum(temp.*temp, dims = 1)))\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_model (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# function load_model(load_dir::String, epoch::Int)\n",
    "#     print(\"Loading model...\")\n",
    "#     @load joinpath(load_dir, \"model-$epoch.bson\") encoder_μ encoder_logvar decoder\n",
    "#     println(\"Done\")\n",
    "#     return encoder_μ, encoder_logvar, decoder\n",
    "# end\n",
    "\n",
    "# function load_model_identity(load_dir::String, epoch::Int)\n",
    "#     print(\"Loading model...\")\n",
    "#     @load joinpath(load_dir, \"model-$epoch.bson\") encoder_μ encoder_logvar decoder decoder_last\n",
    "#     println(\"Done\")\n",
    "#     return encoder_μ, encoder_logvar, decoder, decoder_last\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relative_error (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "function relative_error(z₀, z_est)\n",
    "    return(norm(z₀ - z_est, 2)/ norm(z₀, 2))\n",
    "end  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "perturbed_weights (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function perturbed_weights(x, n)\n",
    "    A = x\n",
    "    for i in 1:n-1\n",
    "        A = hcat(A, a + randn(length(x)))\n",
    "    end\n",
    "    _, s, _ = svd(A)\n",
    "    A = A/s[1];\n",
    "    return A\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the compressed sensing problem of recovering $x\\in\\mathbb{R}^n$ from noisy measurements of the form\n",
    "\n",
    "$$y = A x_{0} + \\epsilon, $$\n",
    "\n",
    "where $\\epsilon\\in\\mathbb{R}^n$ is noise and $A$ is the compressive sensing matrix. We assume the unknown signal $x$ lives in the range of known generative model $G:\\mathbb{R}^k \\rightarrow \\mathbb{R}^n$, i.e. $x_{0} = G(z_0)$ for some $z_0 \\in \\mathbb{R}^k$. We assume the generative model $G$ is  fully-connected feedforward network of the form \n",
    "\n",
    "$$ G(x) = A_d\\sigma(A_{d-1} \\cdots \\sigma(A_1 z)\\cdots),$$\n",
    "\n",
    "where $A_i \\in \\mathbb{R}^{n_i \\times n_{i-1}}$ is the weight matrix and $\\sigma(\\cdot)$ is the activation function. We\n",
    "determine the conditions (on $A, G, x_{0}$, \\etc) under which it is possible to (approximately) recover $x_{0}$ from noisy linear measurements $y$ by (approximately) solving an optimization problem of the form\n",
    "\n",
    "$$\\argmin_{z \\in \\mathbb{R}^{k}} \\|b - A G(z) \\|_{2}. $$\n",
    "\n",
    "Although this optimzation problem is non-convex, it has been shown that gradient descent and other descent-type alogorithm can provably converge to the global optima. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function estimated_code(opt, G, y, A, init; max_iter, tolerance, out_toggle = 0)\n",
    "    z_est = init\n",
    "    θ = Flux.params(z_est)\n",
    "    iter = 1\n",
    "    ∇f = 1.0\n",
    "    while ∇f >= tolerance && iter <= max_iter\n",
    "        grads = gradient(() -> loss(z_est, y, G, A), θ)\n",
    "        update!(opt, z_est, grads[z_est])\n",
    "        ∇f = norm(grads[z_est], 2)\n",
    "        iter += 1\n",
    "        if out_toggle != 0 && iter % out_toggle == 0\n",
    "            println(\"====> In Gradient: Iteration: $iter gradient norm: $∇f\")\n",
    "        end\n",
    "    end\n",
    "    return z_est\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function loss(z, y, G, A)\n",
    "    return norm(A*G(z) -y, 2)^2\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_β_α (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function get_β_α(F, A, B, n)\n",
    "    # generate \"uniform\" gapped incoherence\n",
    "    β_list = 0:.001:1\n",
    "    α_list = []\n",
    "    for β in β_list\n",
    "        push!(α_list, subspace_incoherence(F, β * A + (1-β)*B) )\n",
    "        \n",
    "    end\n",
    "\n",
    "    α_list_ideal = LinRange(α_list[1],α_list[end], n)\n",
    "    index_list = []\n",
    "    for α_ideal in α_list_ideal\n",
    "        temp = 0\n",
    "        index = 0\n",
    "        for i in 1:length(α_list)\n",
    "            if abs(temp - α_ideal) > abs(α_list[i] - α_ideal)\n",
    "                temp = α_list[i]\n",
    "                index = i\n",
    "            end\n",
    "        end\n",
    "        push!(index_list, index)\n",
    "    end\n",
    "    β_list = β_list[index_list]\n",
    "    α_list = α_list[index_list]\n",
    "\n",
    "    return β_list, α_list\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = palette([:red,  :orange, :green, :blue, :Indigo], 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"All function imported\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
