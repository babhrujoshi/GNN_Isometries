{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87388d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "using BSON: @save\n",
    "using BSON: @load\n",
    "using CSV\n",
    "using DataFrames: DataFrame\n",
    "using Flux\n",
    "using Flux: logitbinarycrossentropy, binarycrossentropy, BatchNorm\n",
    "using Flux.Data: DataLoader\n",
    "using Flux: chunk\n",
    "using ImageFiltering\n",
    "using MLDatasets: FashionMNIST\n",
    "using ProgressMeter: Progress, next!\n",
    "using Random\n",
    "using Zygote\n",
    "using MLDatasets\n",
    "using Images\n",
    "using ImageIO\n",
    "using LinearAlgebra\n",
    "using FFTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0efe9194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a reshape layer to use in our decoder\n",
    "struct Reshape\n",
    "    shape\n",
    "end\n",
    "Reshape(args...) = Reshape(args)\n",
    "(r::Reshape)(x) = reshape(x, r.shape)\n",
    "Flux.@functor Reshape ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3fbf96e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_vae (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function get_train_loader(batch_size, shuffle::Bool)\n",
    "    # The MNIST training set is made up of 60k 28 by 28 greyscale images\n",
    "    train_x, train_y = MNIST(split=:train)[:]\n",
    "    train_x = 1 .- reshape(train_x, (784, :))\n",
    "    return DataLoader((train_x, train_y), batchsize=batch_size, shuffle=shuffle, partial=false)\n",
    "end\n",
    "\n",
    "function save_model(encoder_μ, encoder_logvar, decoder, W3, save_dir::String, epoch::Int)\n",
    "    print(\"Saving model...\")\n",
    "    let encoder_μ = cpu(encoder_μ), encoder_logvar = cpu(encoder_logvar), decoder = cpu(decoder), W3 = cpu(W3)\n",
    "        @save joinpath(save_dir, \"model-$epoch.bson\") encoder_μ encoder_logvar decoder W3\n",
    "    end\n",
    "    println(\"Done\")\n",
    "end\n",
    "\n",
    "function create_vae()\n",
    "    # Define the encoder and decoder networks\n",
    "    encoder_features = Chain(\n",
    "        Dense(784,500, relu),\n",
    "        Dense(500,500, relu)\n",
    "    )\n",
    "    encoder_μ = Chain(encoder_features, Dense(500, 20))\n",
    "    encoder_logvar = Chain(encoder_features, Dense(500, 20))\n",
    "    \n",
    "    decoder = Chain(\n",
    "        Dense(20, 500, relu, bias = false),\n",
    "        Dense(500,500, relu,bias = false),\n",
    "    )\n",
    "\n",
    "    W3 = randn(784,500)\n",
    "    return encoder_μ, encoder_logvar, decoder, W3\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e4fca59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function vae_loss(encoder_μ, encoder_logvar, decoder, W3, x, β, λ, F)\n",
    "    batch_size = size(x)[end]\n",
    "    @assert batch_size != 0\n",
    "\n",
    "    # Forward propagate through mean encoder and std encoders\n",
    "    μ = encoder_μ(x)\n",
    "    logvar = encoder_logvar(x)\n",
    "    # Apply reparameterisation trick to sample latent\n",
    "    z = μ + randn(Float32, size(logvar)) .* exp.(0.5f0 * logvar)\n",
    "    # Reconstruct from latent sample\n",
    "\n",
    "    scaled_sig(x) = sigmoid(x/10)\n",
    "    x̂ = scaled_sig(W3*decoder(z))\n",
    "\n",
    "    loss_α(F,A) = maximum(sqrt.(sum((F*A).*(F*A), dims = 2))) + 100*norm(A'*A - I(500),2)^2\n",
    "\n",
    "    α = loss_α(F, W3)\n",
    "    \n",
    "    # Negative reconstruction loss Ε_q[logp_x_z]\n",
    "    logp_x_z = -sum(binarycrossentropy.(x̂, x)) \n",
    "    # KL(qᵩ(z|x)||p(z)) where p(z)=N(0,1) and qᵩ(z|x) models the encoder i.e. reverse KL\n",
    "    # The @. macro makes sure that all operates are elementwise\n",
    "    kl_q_p = 0.5f0 * sum(@. (exp(logvar) + μ^2 - logvar - 1f0)) \n",
    "    # Weight decay regularisation term\n",
    "    reg = λ * sum(x->sum(x.^2), Flux.params(encoder_μ, encoder_logvar, decoder, W3))\n",
    "    # We want to maximise the evidence lower bound (ELBO)\n",
    "    elbo = logp_x_z - β .* kl_q_p\n",
    "    # So we minimise the sum of the negative ELBO and a weight penalty\n",
    "    return -elbo + reg + 10000 * α \n",
    "end\n",
    "\n",
    "function train(encoder_μ, encoder_logvar, decoder, W3, dataloader, num_epochs, λ, β, optimiser, save_dir)\n",
    "    # The training loop for the model\n",
    "    trainable_params = Flux.params(encoder_μ, encoder_logvar, decoder, W3)\n",
    "    progress_tracker = Progress(num_epochs, \"Training a epoch done\")\n",
    "    F = dct(diagm(ones(784)),2);\n",
    "\n",
    "    for epoch_num = 1:num_epochs\n",
    "        acc_loss = 0.0\n",
    "        loss = 0\n",
    "        for (x_batch, y_batch) in dataloader\n",
    "            # x_batch[x_batch .> .8] .= .8; x_batch[x_batch .< .2]  .= .2\n",
    "\n",
    "            # pullback function returns the result (loss) and a pullback operator (back)\n",
    "            loss, back = pullback(trainable_params) do\n",
    "                vae_loss(encoder_μ, encoder_logvar, decoder, W3, x_batch, β, λ, F)\n",
    "            end\n",
    "            # Feed the pullback 1 to obtain the gradients and update then model parameters\n",
    "            gradients = back(1f0)\n",
    "            Flux.Optimise.update!(optimiser, trainable_params, gradients)\n",
    "            if isnan(loss)\n",
    "                break\n",
    "            end\n",
    "            acc_loss += loss\n",
    "        end\n",
    "        next!(progress_tracker; showvalues=[(:loss, loss)])\n",
    "        @assert length(dataloader) > 0\n",
    "        avg_loss = acc_loss / length(dataloader)\n",
    "        metrics = DataFrame(epoch=epoch_num, negative_elbo=avg_loss)\n",
    "        # println(metrics)\n",
    "        CSV.write(joinpath(save_dir, \"metrics.csv\"), metrics, header=(epoch_num==1), append=true)\n",
    "        save_model(encoder_μ, encoder_logvar, decoder, W3, save_dir, epoch_num)\n",
    "    end\n",
    "    println(\"Training complete!\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "339ecd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[32mTraining a epoch done   5%|█▌                            |  ETA: 1:54:07\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  1.317853186348509e13\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done   8%|██▎                           |  ETA: 1:53:07\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  4.405193428851618e12\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  10%|███                           |  ETA: 1:51:19\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  1.6773787684261506e12\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  12%|███▊                          |  ETA: 1:48:58\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  6.8014288209119e11\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  15%|████▌                         |  ETA: 1:45:57\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  2.8377871422090656e11\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  18%|█████▎                        |  ETA: 1:42:55\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  1.1941272559624266e11\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  20%|██████                        |  ETA: 1:39:44\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  4.9986174299120026e10\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  22%|██████▊                       |  ETA: 1:36:32\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  2.0574215250785698e10\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  25%|███████▌                      |  ETA: 1:33:27\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  8.222023818806994e9\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  28%|████████▎                     |  ETA: 1:30:39\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  3.1370594427024097e9\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  30%|█████████                     |  ETA: 1:27:52\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  1.1144018852238374e9\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  32%|█████████▊                    |  ETA: 1:25:04\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  3.541124226452569e8\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  35%|██████████▌                   |  ETA: 1:22:20\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  9.41970467744908e7\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  38%|███████████▎                  |  ETA: 1:19:34\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  1.8750381255679525e7\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  40%|████████████                  |  ETA: 1:16:36\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  2.3224692636471535e6\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  42%|████████████▊                 |  ETA: 1:13:30\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  158435.8805471301\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  45%|█████████████▌                |  ETA: 1:10:23\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  34385.44507516215\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  48%|██████████████▎               |  ETA: 1:07:19\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  28395.306691473685\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  50%|███████████████               |  ETA: 1:04:14\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  21608.528908455148\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  52%|███████████████▊              |  ETA: 1:01:08\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  18114.510852553118\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  55%|████████████████▌             |  ETA: 0:58:00\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  17851.401237082526\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  58%|█████████████████▎            |  ETA: 0:54:47\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  17738.18190773658\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  60%|██████████████████            |  ETA: 0:51:31\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  16833.13145871318\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  62%|██████████████████▊           |  ETA: 0:48:15\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  16617.193703078952\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  65%|███████████████████▌          |  ETA: 0:44:59\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  15792.936702962514\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  68%|████████████████████▎         |  ETA: 0:41:43\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  16238.838479188757\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  70%|█████████████████████         |  ETA: 0:38:26\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  15700.487726445528\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  72%|█████████████████████▊        |  ETA: 0:35:11\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  15620.618480097839\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  75%|██████████████████████▌       |  ETA: 0:31:57\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  15675.401341267203\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  78%|███████████████████████▎      |  ETA: 0:28:44\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  15769.499368048138\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  80%|████████████████████████      |  ETA: 0:25:40\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  16143.662953883952\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  82%|████████████████████████▊     |  ETA: 0:22:36\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  15772.408952968362\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  85%|█████████████████████████▌    |  ETA: 0:19:20\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  16300.631059626006\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  88%|██████████████████████████▎   |  ETA: 0:16:05\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  16813.914471520526\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  90%|███████████████████████████   |  ETA: 0:12:50\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  16689.678210310572\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  92%|███████████████████████████▊  |  ETA: 0:09:37\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  16569.02549970946\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  95%|████████████████████████████▌ |  ETA: 0:06:24\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  16602.805864108293\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  98%|█████████████████████████████▎|  ETA: 0:03:11\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  17058.075722155932\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done 100%|██████████████████████████████| Time: 2:07:26\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  16850.80005229786\u001b[39m\u001b[K\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "shuffle_data = true\n",
    "η = 0.001\n",
    "β = 1f0\n",
    "λ = 0.01f0\n",
    "num_epochs = 40\n",
    "save_dir = \"test/trained_GNN/MNIST_sigmoid_v2\"\n",
    "# Define the model and create our data loader\n",
    "dataloader = get_train_loader(batch_size, shuffle_data)\n",
    "encoder_μ, encoder_logvar, decoder, W3 = create_vae()\n",
    "train(encoder_μ, encoder_logvar, decoder, W3, dataloader, num_epochs, λ, β, ADAM(η), save_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26330dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "visualise (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function get_test_loader(batch_size, shuffle::Bool)\n",
    "    # The FashionMNIST test set is made up of 10k 28 by 28 greyscale images\n",
    "    test_x, test_y = MNIST(split=:test)[:]\n",
    "    test_x = 1 .- reshape(test_x, (784, :))\n",
    "    return DataLoader((test_x, test_y), batchsize=batch_size, shuffle=shuffle)\n",
    "end\n",
    "\n",
    "function save_to_images(x_batch, save_dir::String, prefix::String, num_images::Int64)\n",
    "    @assert num_images <= size(x_batch)[2]\n",
    "    for i=1:num_images\n",
    "        save(joinpath(save_dir, \"$prefix-$i.png\"), colorview(Gray, reshape(x_batch[:, i], 28,28)' ))\n",
    "    end\n",
    "end\n",
    "\n",
    "function reconstruct_images(encoder_μ, encoder_logvar, decoder, W3, x)\n",
    "    # Forward propagate through mean encoder and std encoders\n",
    "    μ = encoder_μ(x)\n",
    "    logvar = encoder_logvar(x)\n",
    "    # Apply reparameterisation trick to sample latent\n",
    "    z = μ + randn(Float32, size(logvar)) .* exp.(0.5f0 * logvar)\n",
    "    # Reconstruct from latent sample\n",
    "\n",
    "    x̂ = sigmoid(W3*decoder(z))\n",
    "    return clamp.(x̂, 0 ,1)\n",
    "end\n",
    "\n",
    "function load_model_identity(load_dir::String, epoch::Int)\n",
    "    print(\"Loading model...\")\n",
    "    @load joinpath(load_dir, \"model-$epoch.bson\") encoder_μ encoder_logvar decoder W3\n",
    "    println(\"Done\")\n",
    "    return encoder_μ, encoder_logvar, decoder, W3\n",
    "end\n",
    "\n",
    "function visualise()\n",
    "    # Define some parameters\n",
    "    batch_size = 1\n",
    "    shuffle = true\n",
    "    num_images = 1\n",
    "    epoch_to_load = 20\n",
    "    # Load the model and test set loader\n",
    "    dir = \"test/trained_GNN/MNIST_sigmoid_inco\"\n",
    "    encoder_μ, encoder_logvar, decoder, W3 = load_model_identity(dir, epoch_to_load)\n",
    "    dataloader = get_test_loader(batch_size, shuffle)\n",
    "    # Reconstruct and save some images\n",
    "    for (x_batch, y_batch) in dataloader\n",
    "        save_to_images(x_batch, dir, \"test-image\", num_images)\n",
    "        x̂_batch = reconstruct_images(encoder_μ, encoder_logvar, decoder, W3, x_batch)\n",
    "        print(size(x_batch))\n",
    "        save_to_images(x̂_batch, dir, \"reconstruction\", num_images)\n",
    "        break\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "eaf26eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...Done"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(784, 1)"
     ]
    }
   ],
   "source": [
    "visualise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "04c4dff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAA8lJREFUaAW9wbuOnWcVANC1z9lnLsR2BjsXZ2wZJ0gkUBBASgMpEAghQCAqKkpaeAZaXoAOHsASZQquQqFAkSCiCLFisHHIBeEIA8qQiee2sfSN9M/xnBRQ7LWy/O8K4f+TmqVmqVn6AGVZoAyBQlhWTgvLUrPULDVLxwphKKcVwiQMhQOkSaAMZQhDapaapWbpWKCsFj5YYGEok0AhUCapWWqWmqVjZbVCoCwLq4VJoAyFQGqWmqVmaYXCf0yODDu4h/eReAgPYY7CAgvMEAiEoQypWWqWmqUHHOKv+CNu4R2cwzpexhbm+DPO4AJ2cQ8X8S08jQ9hblkhNUvNUrN0XxkOcBsv4gWTy9gxFDawjXdwF3/CHZzHHr6DbWxhbihDapaapWbphD38Br/Fo9jARazjLziPj2ILuwg8huv4Jd7EDn6Hz+MsAmGSmqVmqVk6dojfYw1fxBX8E1dwAzOcweP4CBZYxzqewlVcw+t4Dvs4clpqlpqlZlmGOZ7CJczwhOEe9nADa9jBHVzAGgqbSNzEP/Am1g1hWWqWmqVm6YQnsIcNkwWexCfxCn5muIxv42G8gR/iZVzBp3EBa4ZAGVKz1Cw1y0AZApsoBAoznMPzeASv4SW8hScRuIZXsYdn8QVsIhAok9QsNUvN0gphCBQSD+NTeB43sYmX8DbuYIHH8X2cw8xqqVlqlpqlY2EohEmYJD6DW3gL/0ZhA9v4Gq5ibijLAqlZapaapfsCZQhDIZz2YTyGP2AXc1zCOXwdC5NAmRRSs9QsNUsPKITTCm/jx3gBZ3EJb+A2nsYCYVKGQBlSs9QsNUsrHCEsexffw6+whW/iGfwUN3EdiUKgDIFCoJCapWapWTqhEIZCGI7wI/wCh/g4voJHUHgR7+N1XEEYwhAoQ2qWmqVm6b6yrDAzFHbxcxziPL6LT+AAl3AWh5iZhNVSs9QsNUsnBAIzFMJQOMQZfBWfwwIH2MMm1rCGmaEQKIQhkJqlZqlZOqGsNsM3sI9tvIt17ONfSFzGRcsKgTJJzVKz1CzdFyjsY80QOEJgDV/GDnZxHVvYw09wG5t4D4eYmZRlqVlqlpqlE9YsC8MMl/El/BrX8Df8HbdQmOMe9jHHzGqpWWqWmqVjgTIUZjjAHIEFPob38Apu4C728Ciew1mkIXCEMIQhNUvNUrO0QuAIc0MhkHgGP8BreBV3cRXPYhsLBAphCJPULDVLzdIJgTKEIRA4wgbWDRfwWQQODYmyLCxLzVKz1Cw9IFAmZQiUyQyFQqJQhkBZLTVLzVKz/wJTaNoI8or5TwAAAABJRU5ErkJggg==",
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAA8lJREFUaAW9wbuOnWcVANC1z9lnLsR2BjsXZ2wZJ0gkUBBASgMpEAghQCAqKkpaeAZaXoAOHsASZQquQqFAkSCiCLFisHHIBeEIA8qQiee2sfSN9M/xnBRQ7LWy/O8K4f+TmqVmqVn6AGVZoAyBQlhWTgvLUrPULDVLxwphKKcVwiQMhQOkSaAMZQhDapaapWbpWKCsFj5YYGEok0AhUCapWWqWmqVjZbVCoCwLq4VJoAyFQGqWmqVmaYXCf0yODDu4h/eReAgPYY7CAgvMEAiEoQypWWqWmqUHHOKv+CNu4R2cwzpexhbm+DPO4AJ2cQ8X8S08jQ9hblkhNUvNUrN0XxkOcBsv4gWTy9gxFDawjXdwF3/CHZzHHr6DbWxhbihDapaapWbphD38Br/Fo9jARazjLziPj2ILuwg8huv4Jd7EDn6Hz+MsAmGSmqVmqVk6dojfYw1fxBX8E1dwAzOcweP4CBZYxzqewlVcw+t4Dvs4clpqlpqlZlmGOZ7CJczwhOEe9nADa9jBHVzAGgqbSNzEP/Am1g1hWWqWmqVm6YQnsIcNkwWexCfxCn5muIxv42G8gR/iZVzBp3EBa4ZAGVKz1Cw1y0AZApsoBAoznMPzeASv4SW8hScRuIZXsYdn8QVsIhAok9QsNUvN0gphCBQSD+NTeB43sYmX8DbuYIHH8X2cw8xqqVlqlpqlY2EohEmYJD6DW3gL/0ZhA9v4Gq5ibijLAqlZapaapfsCZQhDIZz2YTyGP2AXc1zCOXwdC5NAmRRSs9QsNUsPKITTCm/jx3gBZ3EJb+A2nsYCYVKGQBlSs9QsNUsrHCEsexffw6+whW/iGfwUN3EdiUKgDIFCoJCapWapWTqhEIZCGI7wI/wCh/g4voJHUHgR7+N1XEEYwhAoQ2qWmqVm6b6yrDAzFHbxcxziPL6LT+AAl3AWh5iZhNVSs9QsNUsnBAIzFMJQOMQZfBWfwwIH2MMm1rCGmaEQKIQhkJqlZqlZOqGsNsM3sI9tvIt17ONfSFzGRcsKgTJJzVKz1CzdFyjsY80QOEJgDV/GDnZxHVvYw09wG5t4D4eYmZRlqVlqlpqlE9YsC8MMl/El/BrX8Df8HbdQmOMe9jHHzGqpWWqWmqVjgTIUZjjAHIEFPob38Apu4C728Ciew1mkIXCEMIQhNUvNUrO0QuAIc0MhkHgGP8BreBV3cRXPYhsLBAphCJPULDVLzdIJgTKEIRA4wgbWDRfwWQQODYmyLCxLzVKz1Cw9IFAmZQiUyQyFQqJQhkBZLTVLzVKz/wJTaNoI8or5TwAAAABJRU5ErkJg\">"
      ],
      "text/plain": [
       "28×28 Array{Gray{N0f8},2} with eltype Gray{N0f8}:\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)    Gray{N0f8}(1.0)    …  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)    Gray{N0f8}(1.0)       Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)    Gray{N0f8}(0.996)     Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)    Gray{N0f8}(1.0)       Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)    Gray{N0f8}(0.996)     Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)    Gray{N0f8}(0.996)  …  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)    Gray{N0f8}(0.996)     Gray{N0f8}(0.996)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(0.996)  Gray{N0f8}(0.996)     Gray{N0f8}(0.996)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(0.996)  Gray{N0f8}(0.996)     Gray{N0f8}(0.996)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(0.996)  Gray{N0f8}(0.984)     Gray{N0f8}(0.996)\n",
       " ⋮                                                      ⋱  \n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(0.996)  Gray{N0f8}(0.996)     Gray{N0f8}(0.996)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(0.996)  Gray{N0f8}(0.996)  …  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(0.996)  Gray{N0f8}(0.996)     Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)    Gray{N0f8}(0.996)     Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)    Gray{N0f8}(0.996)     Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)    Gray{N0f8}(1.0)       Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)    Gray{N0f8}(1.0)    …  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)    Gray{N0f8}(1.0)       Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)    Gray{N0f8}(1.0)       Gray{N0f8}(1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "load(\"test/trained_GNN/MNIST_sigmoid_inco/reconstruction-1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ecd198a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAmRJREFUaAW9wT2I1gUAB+Dn5BeheIGIUlstBTYUBlFIYLQUgYqEQUS4Jd0WGZSUigj2tUUJWUMozh4Uigg29IFBUINCONVwEjoEgrV0Df/hRXyv938Qv+fJsq4oi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7IoiylewSmD09jj/xNlURZlMcVuLOImjmA7NrvdVRzB/dht8IjZoizKoiym2IUX8Tmu4Fl8hftM3MApg6MGO7APj2Gj6aIsyqIsVvAh7sGn+Bl7cc7EVpzDXiwZnMEituMwtrlTlEVZlMUK5vEB5nEY3+BJLGIT7sIz+AUncBYXDS7iM2xzpyiLsiiLGd7FMt7HJdyLq3jAYAP2Yz8WcNxgnemiLMqiLEY4iIfwssEOXMBmE3/gOObwNI6aLsqiLMpipOdxFAdwBTvxvcEJfGTiTWwwXZRFWZTFSPN4DZdwBj/hANbiGP4y2IUnrCzKoizKYhXmcRJ78DXec7t1eBvzVhZlURZlsUo/4iL+wRoTm3DNbFEWZVEWI93Cr3gVt7AGcwZb8J1xoizKoixG+BtfYsHELmzEF7iMy3jcbFEWZVEWI3yLBRPH8AZu4TJ+wA5cM1uURVmUxQhnTWzBPoO1WG9w3ThRFmVRFiMsYxkP4gLWm3gd5w0O46D/FmVRFmUxwhzmcBO/Y5OJs5gz+M1sURZlURYjvITTWMJOPIyncAMnTTxntiiLsiiLER7FGbyFC1jCecy53Qtmi7Ioi7IYaSsW8Sc+wXUcN9iCd4wTZVEWZbEKd2MzDhl8bPWiLMqiLMqiLMqiLMqiLMqi7F8hd2JXtfxWpAAAAABJRU5ErkJggg==",
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAmRJREFUaAW9wT2I1gUAB+Dn5BeheIGIUlstBTYUBlFIYLQUgYqEQUS4Jd0WGZSUigj2tUUJWUMozh4Uigg29IFBUINCONVwEjoEgrV0Df/hRXyv938Qv+fJsq4oi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7IoiylewSmD09jj/xNlURZlMcVuLOImjmA7NrvdVRzB/dht8IjZoizKoiym2IUX8Tmu4Fl8hftM3MApg6MGO7APj2Gj6aIsyqIsVvAh7sGn+Bl7cc7EVpzDXiwZnMEituMwtrlTlEVZlMUK5vEB5nEY3+BJLGIT7sIz+AUncBYXDS7iM2xzpyiLsiiLGd7FMt7HJdyLq3jAYAP2Yz8WcNxgnemiLMqiLEY4iIfwssEOXMBmE3/gOObwNI6aLsqiLMpipOdxFAdwBTvxvcEJfGTiTWwwXZRFWZTFSPN4DZdwBj/hANbiGP4y2IUnrCzKoizKYhXmcRJ78DXec7t1eBvzVhZlURZlsUo/4iL+wRoTm3DNbFEWZVEWI93Cr3gVt7AGcwZb8J1xoizKoixG+BtfYsHELmzEF7iMy3jcbFEWZVEWI3yLBRPH8AZu4TJ+wA5cM1uURVmUxQhnTWzBPoO1WG9w3ThRFmVRFiMsYxkP4gLWm3gd5w0O46D/FmVRFmUxwhzmcBO/Y5OJs5gz+M1sURZlURYjvITTWMJOPIyncAMnTTxntiiLsiiLER7FGbyFC1jCecy53Qtmi7Ioi7IYaSsW8Sc+wXUcN9iCd4wTZVEWZbEKd2MzDhl8bPWiLMqiLMqiLMqiLMqiLMqi7F8hd2JXtfxWpAAAAABJRU5ErkJg\">"
      ],
      "text/plain": [
       "28×28 Array{Gray{N0f8},2} with eltype Gray{N0f8}:\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " ⋮                                 ⋱                   \n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "load(\"test/trained_GNN/MNIST_sigmoid_inco/test-image-1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f0f22c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All function imported\n",
      "Loading model...Done"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAA8hJREFUaAW9wd9rX3cZAODnPd83adosienari5DkE2nICh4p///hTeCN9OJOukotmJHszVpfnzPeQ18hLMvYXj3Pk8uVoUJ5f8LFBZMVoEyBBaEVWqWmqVmGXYtCKtAWRUChcBkKARmTH5YapaapWZZ7guUoewKlGFBYDFskVgwoRB2pWapWWqWvicMZQiUVaGwoLDFDbbYIvEAgQNMhrBKzVKz1CzDsFgVAmVVmLHFNS7wFV7hEGfYxyMcYd9qY5WapWapWbpTCKsJZbXgFlfY4h2+wj/xGj/DOxzi2DAbJszYGFKz1Cw1yzIUAmVVKMy4xQWu8CX+hgscIQwHeIBAYYsJiUIgNUvNUrN0JxAo9y24wQ3O8QIv8A5P8Sk2eIANCnvYRxkCYUjNUrPULN0pQyGsFgRucYlv8A8s+BxnODF8gwmH+MAwoRAoBFKz1Cw1S/9TCLsCW8x4gy9xjiP8CJ8gkIb3mBGGBWFXapaapWbpThgKYdeMS/wd59jDZ/gEiYe4xhVuDTMmTChDGFKz1Cw1y0Ah3Fd4j7/gC3yHT/ERDnGIwAUucYNrBCZDYMHGkJqlZqlZlqFQhkBhwS2+xp/wGxxjMmwx4wLXmLHgBnuYDGGVmqVmqVkGyhAIQ2HGJV7iveE5DnCDK9zgFV7icyzYNxQCE8qQmqVmqVkWFmywxcZqwTu8wT6OscU1JlzhFq9xgrd4jBl7CATKEEjNUrPULN2ZDBurwowZH+M5PsJTnKLwCOc4xjku8RyBsKsQSM1Ss9Qs3QkUCoFCYYMtjvAZzvAMgQUzDrCHLU5xg3DfZEjNUrPULH1PoKxuMeFDwwc4QOAK7zHjGi+wh1NDYEIZttggNUvNUrMMFAphCMxY8B+8xI9xhEQh8BZv8RKFLR4hEShDYGNIzVKz1CzLEIawKtzgNb7GTzBhxluc4wv8FSd4jhNs/LDULDVLzTIMMyYECnvYxzM8w5/xGGf4Ft/iX3iDffwCv8IDTIYwFMKQmqVmqVmWYTKUIbCPM3yM7/AHnOAQL7HBBr/E7/AEEwphVyGQmqVmqVmGoQyBMiRO8Xsc44/4N36KEzzFz/EYTzAhEIayChRSs9QsNUt3yhAoqwkH+BC/xa/xCg8x4QCn2MceJhQCYSgECoHULDVLzbIMgbKrEHiINDzBhC02KGwwYTKUVRgChdQsNUvN0p1AIVCGsCrs2bWxCrsmQxkKYUjNUrPULANlFShDGAILAmWYUIawCveFVWqWmqVmWQirMhTCakIhDGFXGAphCLsCqVlqlpr9FzaDCPy46AqFAAAAAElFTkSuQmCC",
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAA8hJREFUaAW9wd9rX3cZAODnPd83adosienari5DkE2nICh4p///hTeCN9OJOukotmJHszVpfnzPeQ18hLMvYXj3Pk8uVoUJ5f8LFBZMVoEyBBaEVWqWmqVmGXYtCKtAWRUChcBkKARmTH5YapaapWZZ7guUoewKlGFBYDFskVgwoRB2pWapWWqWvicMZQiUVaGwoLDFDbbYIvEAgQNMhrBKzVKz1CzDsFgVAmVVmLHFNS7wFV7hEGfYxyMcYd9qY5WapWapWbpTCKsJZbXgFlfY4h2+wj/xGj/DOxzi2DAbJszYGFKz1Cw1yzIUAmVVKMy4xQWu8CX+hgscIQwHeIBAYYsJiUIgNUvNUrN0JxAo9y24wQ3O8QIv8A5P8Sk2eIANCnvYRxkCYUjNUrPULN0pQyGsFgRucYlv8A8s+BxnODF8gwmH+MAwoRAoBFKz1Cw1S/9TCLsCW8x4gy9xjiP8CJ8gkIb3mBGGBWFXapaapWbpThgKYdeMS/wd59jDZ/gEiYe4xhVuDTMmTChDGFKz1Cw1y0Ah3Fd4j7/gC3yHT/ERDnGIwAUucYNrBCZDYMHGkJqlZqlZlqFQhkBhwS2+xp/wGxxjMmwx4wLXmLHgBnuYDGGVmqVmqVkGyhAIQ2HGJV7iveE5DnCDK9zgFV7icyzYNxQCE8qQmqVmqVkWFmywxcZqwTu8wT6OscU1JlzhFq9xgrd4jBl7CATKEEjNUrPULN2ZDBurwowZH+M5PsJTnKLwCOc4xjku8RyBsKsQSM1Ss9Qs3QkUCoFCYYMtjvAZzvAMgQUzDrCHLU5xg3DfZEjNUrPULH1PoKxuMeFDwwc4QOAK7zHjGi+wh1NDYEIZttggNUvNUrMMFAphCMxY8B+8xI9xhEQh8BZv8RKFLR4hEShDYGNIzVKz1CzLEIawKtzgNb7GTzBhxluc4wv8FSd4jhNs/LDULDVLzTIMMyYECnvYxzM8w5/xGGf4Ft/iX3iDffwCv8IDTIYwFMKQmqVmqVmWYTKUIbCPM3yM7/AHnOAQL7HBBr/E7/AEEwphVyGQmqVmqVmGoQyBMiRO8Xsc44/4N36KEzzFz/EYTzAhEIayChRSs9QsNUt3yhAoqwkH+BC/xa/xCg8x4QCn2MceJhQCYSgECoHULDVLzbIMgbKrEHiINDzBhC02KGwwYTKUVRgChdQsNUvN0p1AIVCGsCrs2bWxCrsmQxkKYUjNUrPULANlFShDGAILAmWYUIawCveFVWqWmqVmWQirMhTCakIhDGFXGAphCLsCqVlqlpr9FzaDCPy46AqFAAAAAElFTkSuQmCC\">"
      ],
      "text/plain": [
       "28×28 reinterpret(reshape, Gray{Float64}, adjoint(::Matrix{Float64})) with eltype Gray{Float64}:\n",
       " Gray{Float64}(0.995952)  Gray{Float64}(0.996749)  …  Gray{Float64}(0.994749)\n",
       " Gray{Float64}(0.998081)  Gray{Float64}(0.99873)      Gray{Float64}(0.994809)\n",
       " Gray{Float64}(0.996116)  Gray{Float64}(0.997759)     Gray{Float64}(0.996762)\n",
       " Gray{Float64}(0.997287)  Gray{Float64}(0.997692)     Gray{Float64}(0.994547)\n",
       " Gray{Float64}(0.998494)  Gray{Float64}(0.998049)     Gray{Float64}(0.996714)\n",
       " Gray{Float64}(0.998134)  Gray{Float64}(0.994923)  …  Gray{Float64}(0.99646)\n",
       " Gray{Float64}(0.996869)  Gray{Float64}(0.995295)     Gray{Float64}(0.996575)\n",
       " Gray{Float64}(0.996462)  Gray{Float64}(0.99876)      Gray{Float64}(0.996997)\n",
       " Gray{Float64}(0.997298)  Gray{Float64}(0.99794)      Gray{Float64}(0.997653)\n",
       " Gray{Float64}(0.995882)  Gray{Float64}(0.994176)     Gray{Float64}(0.997692)\n",
       " ⋮                                                 ⋱  \n",
       " Gray{Float64}(0.996821)  Gray{Float64}(0.997363)     Gray{Float64}(0.997708)\n",
       " Gray{Float64}(0.99922)   Gray{Float64}(0.999328)  …  Gray{Float64}(0.999295)\n",
       " Gray{Float64}(0.996257)  Gray{Float64}(0.997565)     Gray{Float64}(0.999365)\n",
       " Gray{Float64}(0.998825)  Gray{Float64}(0.998189)     Gray{Float64}(0.995595)\n",
       " Gray{Float64}(0.999049)  Gray{Float64}(0.997956)     Gray{Float64}(0.99884)\n",
       " Gray{Float64}(0.996085)  Gray{Float64}(0.996589)     Gray{Float64}(0.9962)\n",
       " Gray{Float64}(0.997404)  Gray{Float64}(0.999681)  …  Gray{Float64}(0.995264)\n",
       " Gray{Float64}(0.998285)  Gray{Float64}(0.996992)     Gray{Float64}(0.997906)\n",
       " Gray{Float64}(0.99588)   Gray{Float64}(0.998969)     Gray{Float64}(0.999023)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using NBInclude\n",
    "@nbinclude(\"src/functions.ipynb\")\n",
    "epoch_to_load =40\n",
    "# Load the model and test set loader\n",
    "dir = \"test/trained_GNN/MNIST_sigmoid_inco\"\n",
    "encoder_μ, encoder_logvar, decoder, W3 = load_model_identity(dir, epoch_to_load);\n",
    "\n",
    "\n",
    "batch_size = 64; shuffle = true\n",
    "dataloader = get_test_loader(batch_size, shuffle)\n",
    "(x_batch, y_batch) = first(dataloader)\n",
    "\n",
    "# x = reshape(x_batch[:,1], 784,1)\n",
    "\n",
    "μ = encoder_μ(x_batch)\n",
    "logvar = encoder_logvar(x_batch)\n",
    "# Apply reparameterisation trick to sample latent\n",
    "z = μ + randn(Float32, size(logvar)) .* exp.(0.5f0 * logvar);\n",
    "\n",
    "colorview(Gray,reshape(sigmoid(W3*decoder(z))[:,1], 28,28)')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d46437f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20-element Vector{Float32}:\n",
       " -0.8121152\n",
       "  1.1989852\n",
       "  0.9215686\n",
       " -0.9055035\n",
       " -0.90005434\n",
       " -0.8444268\n",
       "  0.41006792\n",
       " -0.9674509\n",
       "  2.484702\n",
       " -0.64016926\n",
       " -1.6264142\n",
       "  1.0884744\n",
       "  0.5414382\n",
       "  2.6425004\n",
       " -0.9559748\n",
       " -0.6307085\n",
       " -0.3940503\n",
       "  0.97894895\n",
       "  0.07229303\n",
       "  0.65780807"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bf3484",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
