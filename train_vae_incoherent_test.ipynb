{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87388d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "using BSON: @save\n",
    "using BSON: @load\n",
    "using CSV\n",
    "using DataFrames: DataFrame\n",
    "using Flux\n",
    "using Flux: logitbinarycrossentropy, binarycrossentropy, BatchNorm\n",
    "using Flux.Data: DataLoader\n",
    "using Flux: chunk\n",
    "using ImageFiltering\n",
    "using MLDatasets: FashionMNIST\n",
    "using ProgressMeter: Progress, next!\n",
    "using Random\n",
    "using Zygote\n",
    "using MLDatasets\n",
    "using Images\n",
    "using ImageIO\n",
    "using LinearAlgebra\n",
    "using FFTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0efe9194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a reshape layer to use in our decoder\n",
    "struct Reshape\n",
    "    shape\n",
    "end\n",
    "Reshape(args...) = Reshape(args)\n",
    "(r::Reshape)(x) = reshape(x, r.shape)\n",
    "Flux.@functor Reshape ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fbf96e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_vae (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function get_train_loader(batch_size, shuffle::Bool)\n",
    "    # The MNIST training set is made up of 60k 28 by 28 greyscale images\n",
    "    train_x, train_y = MNIST(split=:train)[:]\n",
    "    train_x = 1 .- reshape(train_x, (784, :))\n",
    "    return DataLoader((train_x, train_y), batchsize=batch_size, shuffle=shuffle, partial=false)\n",
    "end\n",
    "\n",
    "function save_model(encoder_μ, encoder_logvar, decoder , save_dir::String, epoch::Int)\n",
    "    print(\"Saving model...\")\n",
    "    let encoder_μ = cpu(encoder_μ), encoder_logvar = cpu(encoder_logvar), decoder = cpu(decoder)\n",
    "        @save joinpath(save_dir, \"model-$epoch.bson\") encoder_μ encoder_logvar decoder\n",
    "    end\n",
    "    println(\"Done\")\n",
    "end\n",
    "\n",
    "function create_vae()\n",
    "    # Define the encoder and decoder networks\n",
    "    encoder_features = Chain(\n",
    "        Dense(784,500, relu),\n",
    "        Dense(500,500, relu)\n",
    "    )\n",
    "    encoder_μ = Chain(encoder_features, Dense(500, 20))\n",
    "    encoder_logvar = Chain(encoder_features, Dense(500, 20))\n",
    "\n",
    "    decoder = Chain(\n",
    "        Dense(20, 500, relu, bias = false),\n",
    "        Dense(500,500, sigmoid, bias = false),\n",
    "        Dense(500, 784, sigmoid, bias = false)\n",
    "    )\n",
    "    return encoder_μ, encoder_logvar, decoder\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4fca59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function vae_loss(encoder_μ, encoder_logvar, decoder, x, β, λ, F)\n",
    "    batch_size = size(x)[end]\n",
    "    @assert batch_size != 0\n",
    "\n",
    "    # Forward propagate through mean encoder and std encoders\n",
    "    μ = encoder_μ(x)\n",
    "    logvar = encoder_logvar(x)\n",
    "    # Apply reparameterisation trick to sample latent\n",
    "    z = μ + randn(Float32, size(logvar)) .* exp.(0.5f0 * logvar)\n",
    "    # Reconstruct from latent sample\n",
    "\n",
    "\n",
    "    x̂ = decoder(z)\n",
    "    # x̂ = sigmoid(W3*relu(W2*relu(W1*z)))\n",
    "\n",
    "    loss_α(F,A) = maximum(sqrt.(sum((F*A).*(F*A), dims = 2))) + 100*norm(A'*A - I(500),2)^2\n",
    "\n",
    "    α = loss_α(F, Flux.params(decoder)[3])\n",
    "\n",
    "\n",
    "    # Negative reconstruction loss Ε_q[logp_x_z]\n",
    "    logp_x_z = -sum(binarycrossentropy.(x̂, x)) \n",
    "    # KL(qᵩ(z|x)||p(z)) where p(z)=N(0,1) and qᵩ(z|x) models the encoder i.e. reverse KL\n",
    "    # The @. macro makes sure that all operates are elementwise\n",
    "    kl_q_p = 0.5f0 * sum(@. (exp(logvar) + μ^2 - logvar - 1f0)) \n",
    "    # Weight decay regularisation term\n",
    "    reg = λ * sum(x->sum(x.^2), Flux.params(encoder_μ, encoder_logvar, decoder))\n",
    "    # We want to maximise the evidence lower bound (ELBO)\n",
    "    elbo = logp_x_z - β .* kl_q_p\n",
    "    # So we minimise the sum of the negative ELBO and a weight penalty\n",
    "    return -elbo + reg + 10000 * α \n",
    "end\n",
    "\n",
    "function train(encoder_μ, encoder_logvar, decoder, dataloader, num_epochs, λ, β, optimiser, save_dir)\n",
    "    # The training loop for the model\n",
    "    trainable_params = Flux.params(encoder_μ, encoder_logvar, decoder)\n",
    "    progress_tracker = Progress(num_epochs, \"Training a epoch done\")\n",
    "    F = dct(diagm(ones(784)),2);\n",
    "\n",
    "    for epoch_num = 1:num_epochs\n",
    "        acc_loss = 0.0\n",
    "        loss = 0\n",
    "        for (x_batch, y_batch) in dataloader\n",
    "            # x_batch[x_batch .> .8] .= .8; x_batch[x_batch .< .2]  .= .2\n",
    "\n",
    "            # pullback function returns the result (loss) and a pullback operator (back)\n",
    "            loss, back = pullback(trainable_params) do\n",
    "                vae_loss(encoder_μ, encoder_logvar, decoder, x_batch, β, λ, F)\n",
    "            end\n",
    "            # Feed the pullback 1 to obtain the gradients and update then model parameters\n",
    "            gradients = back(1f0)\n",
    "            Flux.Optimise.update!(optimiser, trainable_params, gradients)\n",
    "            if isnan(loss)\n",
    "                break\n",
    "            end\n",
    "            acc_loss += loss\n",
    "        end\n",
    "        next!(progress_tracker; showvalues=[(:loss, loss)])\n",
    "        @assert length(dataloader) > 0\n",
    "        avg_loss = acc_loss / length(dataloader)\n",
    "        metrics = DataFrame(epoch=epoch_num, negative_elbo=avg_loss)\n",
    "        # println(metrics)\n",
    "        CSV.write(joinpath(save_dir, \"metrics.csv\"), metrics, header=(epoch_num==1), append=true)\n",
    "        save_model(encoder_μ, encoder_logvar, decoder, save_dir, epoch_num)\n",
    "    end\n",
    "    println(\"Training complete!\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "339ecd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "shuffle_data = true\n",
    "η = 0.001\n",
    "β = 1f0\n",
    "λ = 0.01f0\n",
    "num_epochs = 20\n",
    "save_dir = \"test/trained_GNN/MNIST_sigmoid_inco\"\n",
    "# Define the model and create our data loader\n",
    "dataloader = get_train_loader(batch_size, shuffle_data)\n",
    "encoder_μ, encoder_logvar, decoder = create_vae()\n",
    "train(encoder_μ, encoder_logvar, decoder, dataloader, num_epochs, λ, β, ADAM(η), save_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "26330dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "visualise (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function get_test_loader(batch_size, shuffle::Bool)\n",
    "    # The FashionMNIST test set is made up of 10k 28 by 28 greyscale images\n",
    "    test_x, test_y = MNIST(split=:test)[:]\n",
    "    test_x = 1 .- reshape(test_x, (784, :))\n",
    "    return DataLoader((test_x, test_y), batchsize=batch_size, shuffle=shuffle)\n",
    "end\n",
    "\n",
    "function save_to_images(x_batch, save_dir::String, prefix::String, num_images::Int64)\n",
    "    @assert num_images <= size(x_batch)[2]\n",
    "    for i=1:num_images\n",
    "        save(joinpath(save_dir, \"$prefix-$i.png\"), colorview(Gray, reshape(x_batch[:, i], 28,28)' ))\n",
    "    end\n",
    "end\n",
    "\n",
    "function reconstruct_images(encoder_μ, encoder_logvar, decoder, x)\n",
    "    # Forward propagate through mean encoder and std encoders\n",
    "    μ = encoder_μ(x)\n",
    "    logvar = encoder_logvar(x)\n",
    "    # Apply reparameterisation trick to sample latent\n",
    "    z = μ + randn(Float32, size(logvar)) .* exp.(0.5f0 * logvar)\n",
    "    # Reconstruct from latent sample\n",
    "\n",
    "\n",
    "    # W1 = Flux.params(decoder)[1]\n",
    "    # b1 = Flux.params(decoder)[3]\n",
    "\n",
    "    # W2 = Flux.params(decoder)[5]\n",
    "    # b2 = Flux.params(decoder)[7]\n",
    "\n",
    "    # W3 = Flux.params(decoder)[9]\n",
    "    # b3 = Flux.params(decoder)[11]\n",
    "\n",
    "    # G = Chain(\n",
    "    #     Dense( W1, b1, relu),\n",
    "    #     Dense(W2, b2, relu),\n",
    "    #     Dense(W3, b3, sigmoid)\n",
    "    # )\n",
    "\n",
    "    # x̂ = G(z)\n",
    "\n",
    "    x̂ = decoder(z)\n",
    "    return clamp.(x̂, 0 ,1)\n",
    "end\n",
    "\n",
    "function load_model_identity(load_dir::String, epoch::Int)\n",
    "    print(\"Loading model...\")\n",
    "    @load joinpath(load_dir, \"model-$epoch.bson\") encoder_μ encoder_logvar decoder\n",
    "    println(\"Done\")\n",
    "    return encoder_μ, encoder_logvar, decoder\n",
    "end\n",
    "\n",
    "function visualise()\n",
    "    # Define some parameters\n",
    "    batch_size = 1\n",
    "    shuffle = true\n",
    "    num_images = 1\n",
    "    epoch_to_load = 20\n",
    "    # Load the model and test set loader\n",
    "    dir = \"test/trained_GNN/MNIST_sigmoid_inco\"\n",
    "    encoder_μ, encoder_logvar, decoder = load_model_identity(dir, epoch_to_load)\n",
    "    dataloader = get_test_loader(batch_size, shuffle)\n",
    "    # Reconstruct and save some images\n",
    "    for (x_batch, y_batch) in dataloader\n",
    "        save_to_images(x_batch, dir, \"test-image\", num_images)\n",
    "        x̂_batch = reconstruct_images(encoder_μ, encoder_logvar, decoder, x_batch)\n",
    "        print(size(x_batch))\n",
    "        save_to_images(x̂_batch, dir, \"reconstruction\", num_images)\n",
    "        break\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "eaf26eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...Done"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(784, 1)"
     ]
    }
   ],
   "source": [
    "visualise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "04c4dff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAA8lJREFUaAW9wbuOnWcVANC1z9lnLsR2BjsXZ2wZJ0gkUBBASgMpEAghQCAqKkpaeAZaXoAOHsASZQquQqFAkSCiCLFisHHIBeEIA8qQiee2sfSN9M/xnBRQ7LWy/O8K4f+TmqVmqVn6AGVZoAyBQlhWTgvLUrPULDVLxwphKKcVwiQMhQOkSaAMZQhDapaapWbpWKCsFj5YYGEok0AhUCapWWqWmqVjZbVCoCwLq4VJoAyFQGqWmqVmaYXCf0yODDu4h/eReAgPYY7CAgvMEAiEoQypWWqWmqUHHOKv+CNu4R2cwzpexhbm+DPO4AJ2cQ8X8S08jQ9hblkhNUvNUrN0XxkOcBsv4gWTy9gxFDawjXdwF3/CHZzHHr6DbWxhbihDapaapWbphD38Br/Fo9jARazjLziPj2ILuwg8huv4Jd7EDn6Hz+MsAmGSmqVmqVk6dojfYw1fxBX8E1dwAzOcweP4CBZYxzqewlVcw+t4Dvs4clpqlpqlZlmGOZ7CJczwhOEe9nADa9jBHVzAGgqbSNzEP/Am1g1hWWqWmqVm6YQnsIcNkwWexCfxCn5muIxv42G8gR/iZVzBp3EBa4ZAGVKz1Cw1y0AZApsoBAoznMPzeASv4SW8hScRuIZXsYdn8QVsIhAok9QsNUvN0gphCBQSD+NTeB43sYmX8DbuYIHH8X2cw8xqqVlqlpqlY2EohEmYJD6DW3gL/0ZhA9v4Gq5ibijLAqlZapaapfsCZQhDIZz2YTyGP2AXc1zCOXwdC5NAmRRSs9QsNUsPKITTCm/jx3gBZ3EJb+A2nsYCYVKGQBlSs9QsNUsrHCEsexffw6+whW/iGfwUN3EdiUKgDIFCoJCapWapWTqhEIZCGI7wI/wCh/g4voJHUHgR7+N1XEEYwhAoQ2qWmqVm6b6yrDAzFHbxcxziPL6LT+AAl3AWh5iZhNVSs9QsNUsnBAIzFMJQOMQZfBWfwwIH2MMm1rCGmaEQKIQhkJqlZqlZOqGsNsM3sI9tvIt17ONfSFzGRcsKgTJJzVKz1CzdFyjsY80QOEJgDV/GDnZxHVvYw09wG5t4D4eYmZRlqVlqlpqlE9YsC8MMl/El/BrX8Df8HbdQmOMe9jHHzGqpWWqWmqVjgTIUZjjAHIEFPob38Apu4C728Ciew1mkIXCEMIQhNUvNUrO0QuAIc0MhkHgGP8BreBV3cRXPYhsLBAphCJPULDVLzdIJgTKEIRA4wgbWDRfwWQQODYmyLCxLzVKz1Cw9IFAmZQiUyQyFQqJQhkBZLTVLzVKz/wJTaNoI8or5TwAAAABJRU5ErkJggg==",
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAA8lJREFUaAW9wbuOnWcVANC1z9lnLsR2BjsXZ2wZJ0gkUBBASgMpEAghQCAqKkpaeAZaXoAOHsASZQquQqFAkSCiCLFisHHIBeEIA8qQiee2sfSN9M/xnBRQ7LWy/O8K4f+TmqVmqVn6AGVZoAyBQlhWTgvLUrPULDVLxwphKKcVwiQMhQOkSaAMZQhDapaapWbpWKCsFj5YYGEok0AhUCapWWqWmqVjZbVCoCwLq4VJoAyFQGqWmqVmaYXCf0yODDu4h/eReAgPYY7CAgvMEAiEoQypWWqWmqUHHOKv+CNu4R2cwzpexhbm+DPO4AJ2cQ8X8S08jQ9hblkhNUvNUrN0XxkOcBsv4gWTy9gxFDawjXdwF3/CHZzHHr6DbWxhbihDapaapWbphD38Br/Fo9jARazjLziPj2ILuwg8huv4Jd7EDn6Hz+MsAmGSmqVmqVk6dojfYw1fxBX8E1dwAzOcweP4CBZYxzqewlVcw+t4Dvs4clpqlpqlZlmGOZ7CJczwhOEe9nADa9jBHVzAGgqbSNzEP/Am1g1hWWqWmqVm6YQnsIcNkwWexCfxCn5muIxv42G8gR/iZVzBp3EBa4ZAGVKz1Cw1y0AZApsoBAoznMPzeASv4SW8hScRuIZXsYdn8QVsIhAok9QsNUvN0gphCBQSD+NTeB43sYmX8DbuYIHH8X2cw8xqqVlqlpqlY2EohEmYJD6DW3gL/0ZhA9v4Gq5ibijLAqlZapaapfsCZQhDIZz2YTyGP2AXc1zCOXwdC5NAmRRSs9QsNUsPKITTCm/jx3gBZ3EJb+A2nsYCYVKGQBlSs9QsNUsrHCEsexffw6+whW/iGfwUN3EdiUKgDIFCoJCapWapWTqhEIZCGI7wI/wCh/g4voJHUHgR7+N1XEEYwhAoQ2qWmqVm6b6yrDAzFHbxcxziPL6LT+AAl3AWh5iZhNVSs9QsNUsnBAIzFMJQOMQZfBWfwwIH2MMm1rCGmaEQKIQhkJqlZqlZOqGsNsM3sI9tvIt17ONfSFzGRcsKgTJJzVKz1CzdFyjsY80QOEJgDV/GDnZxHVvYw09wG5t4D4eYmZRlqVlqlpqlE9YsC8MMl/El/BrX8Df8HbdQmOMe9jHHzGqpWWqWmqVjgTIUZjjAHIEFPob38Apu4C728Ciew1mkIXCEMIQhNUvNUrO0QuAIc0MhkHgGP8BreBV3cRXPYhsLBAphCJPULDVLzdIJgTKEIRA4wgbWDRfwWQQODYmyLCxLzVKz1Cw9IFAmZQiUyQyFQqJQhkBZLTVLzVKz/wJTaNoI8or5TwAAAABJRU5ErkJg\">"
      ],
      "text/plain": [
       "28×28 Array{Gray{N0f8},2} with eltype Gray{N0f8}:\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)    Gray{N0f8}(1.0)    …  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)    Gray{N0f8}(1.0)       Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)    Gray{N0f8}(0.996)     Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)    Gray{N0f8}(1.0)       Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)    Gray{N0f8}(0.996)     Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)    Gray{N0f8}(0.996)  …  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)    Gray{N0f8}(0.996)     Gray{N0f8}(0.996)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(0.996)  Gray{N0f8}(0.996)     Gray{N0f8}(0.996)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(0.996)  Gray{N0f8}(0.996)     Gray{N0f8}(0.996)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(0.996)  Gray{N0f8}(0.984)     Gray{N0f8}(0.996)\n",
       " ⋮                                                      ⋱  \n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(0.996)  Gray{N0f8}(0.996)     Gray{N0f8}(0.996)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(0.996)  Gray{N0f8}(0.996)  …  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(0.996)  Gray{N0f8}(0.996)     Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)    Gray{N0f8}(0.996)     Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)    Gray{N0f8}(0.996)     Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)    Gray{N0f8}(1.0)       Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)    Gray{N0f8}(1.0)    …  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)    Gray{N0f8}(1.0)       Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)    Gray{N0f8}(1.0)       Gray{N0f8}(1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "load(\"test/trained_GNN/MNIST_sigmoid_inco/reconstruction-1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ecd198a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAmRJREFUaAW9wT2I1gUAB+Dn5BeheIGIUlstBTYUBlFIYLQUgYqEQUS4Jd0WGZSUigj2tUUJWUMozh4Uigg29IFBUINCONVwEjoEgrV0Df/hRXyv938Qv+fJsq4oi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7IoiylewSmD09jj/xNlURZlMcVuLOImjmA7NrvdVRzB/dht8IjZoizKoiym2IUX8Tmu4Fl8hftM3MApg6MGO7APj2Gj6aIsyqIsVvAh7sGn+Bl7cc7EVpzDXiwZnMEituMwtrlTlEVZlMUK5vEB5nEY3+BJLGIT7sIz+AUncBYXDS7iM2xzpyiLsiiLGd7FMt7HJdyLq3jAYAP2Yz8WcNxgnemiLMqiLEY4iIfwssEOXMBmE3/gOObwNI6aLsqiLMpipOdxFAdwBTvxvcEJfGTiTWwwXZRFWZTFSPN4DZdwBj/hANbiGP4y2IUnrCzKoizKYhXmcRJ78DXec7t1eBvzVhZlURZlsUo/4iL+wRoTm3DNbFEWZVEWI93Cr3gVt7AGcwZb8J1xoizKoixG+BtfYsHELmzEF7iMy3jcbFEWZVEWI3yLBRPH8AZu4TJ+wA5cM1uURVmUxQhnTWzBPoO1WG9w3ThRFmVRFiMsYxkP4gLWm3gd5w0O46D/FmVRFmUxwhzmcBO/Y5OJs5gz+M1sURZlURYjvITTWMJOPIyncAMnTTxntiiLsiiLER7FGbyFC1jCecy53Qtmi7Ioi7IYaSsW8Sc+wXUcN9iCd4wTZVEWZbEKd2MzDhl8bPWiLMqiLMqiLMqiLMqiLMqi7F8hd2JXtfxWpAAAAABJRU5ErkJggg==",
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAmRJREFUaAW9wT2I1gUAB+Dn5BeheIGIUlstBTYUBlFIYLQUgYqEQUS4Jd0WGZSUigj2tUUJWUMozh4Uigg29IFBUINCONVwEjoEgrV0Df/hRXyv938Qv+fJsq4oi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7IoiylewSmD09jj/xNlURZlMcVuLOImjmA7NrvdVRzB/dht8IjZoizKoiym2IUX8Tmu4Fl8hftM3MApg6MGO7APj2Gj6aIsyqIsVvAh7sGn+Bl7cc7EVpzDXiwZnMEituMwtrlTlEVZlMUK5vEB5nEY3+BJLGIT7sIz+AUncBYXDS7iM2xzpyiLsiiLGd7FMt7HJdyLq3jAYAP2Yz8WcNxgnemiLMqiLEY4iIfwssEOXMBmE3/gOObwNI6aLsqiLMpipOdxFAdwBTvxvcEJfGTiTWwwXZRFWZTFSPN4DZdwBj/hANbiGP4y2IUnrCzKoizKYhXmcRJ78DXec7t1eBvzVhZlURZlsUo/4iL+wRoTm3DNbFEWZVEWI93Cr3gVt7AGcwZb8J1xoizKoixG+BtfYsHELmzEF7iMy3jcbFEWZVEWI3yLBRPH8AZu4TJ+wA5cM1uURVmUxQhnTWzBPoO1WG9w3ThRFmVRFiMsYxkP4gLWm3gd5w0O46D/FmVRFmUxwhzmcBO/Y5OJs5gz+M1sURZlURYjvITTWMJOPIyncAMnTTxntiiLsiiLER7FGbyFC1jCecy53Qtmi7Ioi7IYaSsW8Sc+wXUcN9iCd4wTZVEWZbEKd2MzDhl8bPWiLMqiLMqiLMqiLMqiLMqi7F8hd2JXtfxWpAAAAABJRU5ErkJg\">"
      ],
      "text/plain": [
       "28×28 Array{Gray{N0f8},2} with eltype Gray{N0f8}:\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " ⋮                                 ⋱                   \n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "load(\"test/trained_GNN/MNIST_sigmoid_inco/test-image-1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f0f22c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All function imported\n",
      "Loading model...Done"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAA2BJREFUaAW9wc2O3XMYAODn/Z93zLTKtAtFGl+NsBA7XwsuQoQIV2Bt43bsrNyCIG2atLGU0A2JkqGaVlDaOec1ya/Jv2fODLF5nyfL/1eG8P+lZqlZapaOUTYFyqwMgbIpbErNUrPULN1TCENZFyiUIVAowxITJkMZyiwMqVlqlpqlQ8osUCiUYR8r7OM2TmKJkwgEAuVoqVlqlpql+5RZoFAIhCFxFz/hB1zCY3gWr+ABBMJQhkIgNUvNUrN0jDKEIczuYBuf4DIewTt4DWFdGMqQmqVmqVk6JAyFcLST2MaH+AhX8TPS0cpQSM1Ss9QsHVIoTDYVlobCWfyIn7CHQthUCARSs9QsNUsHyrrJpsId3EbhJP7Ad7iJCwjrCoEJhUJqlpqlZlk2lU1/4WtcxQt4DoVbWOF5xyuz1Cw1S83SgUAZAmUoBFbYx1fYwZPYwq+4a9hB2LTChDKkZqlZapYOlCFQCKwQKASu4RJexQnDJZThCZsCYV1qlpqlZhkos0AhEIa7uIxLeBsTbuMbQ+Cc45UhkJqlZqlZOqQMgULhF1zGPn7HHi7gYywwYRuFsK4QKBRSs9QsNUv3KQQKZVjhGi5iCxfxBT7HedzATXyG97CwLlCGQGqWmqVm6UCgDGUIFJa4ilvYw6f4BafwPJ7FF9jDCgubAoVCapaapWbpkEChDInTeAa/4joSu3gLV7CPb/Endv271Cw1S83SPWFTofAiXsc5fIX38TZO4UsE/kaiEDYFCqlZapaaZSFQhjArTHgcb+IK3sXL2MUKz2CBXfyGBx2tDKlZapaaZaDMCoHCZCicxhmcw0OYsMIuTuMsdlEI61YIBFKz1Cw1S0dYIcwmXMAFPIq/kbiL69jCDhaGQpiFWWqWmqVm6ZCyaYkb2MP3eBonsI8zOIVXsY/E5HipWWqWmqUDgUIYyqywxHk8jd+wwHVcR+ENPIU7mHACZVhiYZaapWapWTokEIZCIfASltjCCdzBw/gAt/EAtrGNQmCFhXWpWWqWmqVDCmEILLCDHUMYdvAwCvtYGCaUIczCkJqlZqlZuidQhjKEoRAIszAEtlBYYkKgzMIsNUvNUrN0n0CZFQJhtsJkVgiskDaFdalZapaapf9Q1oVZIQyTWRnCptQsNUvN/gEcP994yCSZiAAAAABJRU5ErkJggg==",
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAA2BJREFUaAW9wc2O3XMYAODn/Z93zLTKtAtFGl+NsBA7XwsuQoQIV2Bt43bsrNyCIG2atLGU0A2JkqGaVlDaOec1ya/Jv2fODLF5nyfL/1eG8P+lZqlZapaOUTYFyqwMgbIpbErNUrPULN1TCENZFyiUIVAowxITJkMZyiwMqVlqlpqlQ8osUCiUYR8r7OM2TmKJkwgEAuVoqVlqlpql+5RZoFAIhCFxFz/hB1zCY3gWr+ABBMJQhkIgNUvNUrN0jDKEIczuYBuf4DIewTt4DWFdGMqQmqVmqVk6JAyFcLST2MaH+AhX8TPS0cpQSM1Ss9QsHVIoTDYVlobCWfyIn7CHQthUCARSs9QsNUsHyrrJpsId3EbhJP7Ad7iJCwjrCoEJhUJqlpqlZlk2lU1/4WtcxQt4DoVbWOF5xyuz1Cw1S83SgUAZAmUoBFbYx1fYwZPYwq+4a9hB2LTChDKkZqlZapYOlCFQCKwQKASu4RJexQnDJZThCZsCYV1qlpqlZhkos0AhEIa7uIxLeBsTbuMbQ+Cc45UhkJqlZqlZOqQMgULhF1zGPn7HHi7gYywwYRuFsK4QKBRSs9QsNUv3KQQKZVjhGi5iCxfxBT7HedzATXyG97CwLlCGQGqWmqVm6UCgDGUIFJa4ilvYw6f4BafwPJ7FF9jDCgubAoVCapaapWbpkEChDInTeAa/4joSu3gLV7CPb/Endv271Cw1S83SPWFTofAiXsc5fIX38TZO4UsE/kaiEDYFCqlZapaaZSFQhjArTHgcb+IK3sXL2MUKz2CBXfyGBx2tDKlZapaaZaDMCoHCZCicxhmcw0OYsMIuTuMsdlEI61YIBFKz1Cw1S0dYIcwmXMAFPIq/kbiL69jCDhaGQpiFWWqWmqVm6ZCyaYkb2MP3eBonsI8zOIVXsY/E5HipWWqWmqUDgUIYyqywxHk8jd+wwHVcR+ENPIU7mHACZVhiYZaapWapWTokEIZCIfASltjCCdzBw/gAt/EAtrGNQmCFhXWpWWqWmqVDCmEILLCDHUMYdvAwCvtYGCaUIczCkJqlZqlZuidQhjKEoRAIszAEtlBYYkKgzMIsNUvNUrN0n0CZFQJhtsJkVgiskDaFdalZapaapf9Q1oVZIQyTWRnCptQsNUvN/gEcP994yCSZiAAAAABJRU5ErkJg\">"
      ],
      "text/plain": [
       "28×28 reinterpret(reshape, Gray{Float64}, adjoint(::Matrix{Float64})) with eltype Gray{Float64}:\n",
       " Gray{Float64}(0.998051)  Gray{Float64}(0.998051)  …  Gray{Float64}(0.998051)\n",
       " Gray{Float64}(0.998051)  Gray{Float64}(0.998051)     Gray{Float64}(0.998051)\n",
       " Gray{Float64}(0.998051)  Gray{Float64}(0.998051)     Gray{Float64}(0.998051)\n",
       " Gray{Float64}(0.998051)  Gray{Float64}(0.998051)     Gray{Float64}(0.998051)\n",
       " Gray{Float64}(0.998051)  Gray{Float64}(0.998051)     Gray{Float64}(0.99805)\n",
       " Gray{Float64}(0.998051)  Gray{Float64}(0.998051)  …  Gray{Float64}(0.998049)\n",
       " Gray{Float64}(0.998051)  Gray{Float64}(0.99805)      Gray{Float64}(0.997954)\n",
       " Gray{Float64}(0.998051)  Gray{Float64}(0.99804)      Gray{Float64}(0.998064)\n",
       " Gray{Float64}(0.998048)  Gray{Float64}(0.997822)     Gray{Float64}(0.99799)\n",
       " Gray{Float64}(0.998026)  Gray{Float64}(0.997183)     Gray{Float64}(0.997981)\n",
       " ⋮                                                 ⋱  \n",
       " Gray{Float64}(0.998051)  Gray{Float64}(0.998034)     Gray{Float64}(0.998047)\n",
       " Gray{Float64}(0.998051)  Gray{Float64}(0.997985)  …  Gray{Float64}(0.99805)\n",
       " Gray{Float64}(0.998051)  Gray{Float64}(0.997999)     Gray{Float64}(0.99805)\n",
       " Gray{Float64}(0.998051)  Gray{Float64}(0.99805)      Gray{Float64}(0.99805)\n",
       " Gray{Float64}(0.998051)  Gray{Float64}(0.998051)     Gray{Float64}(0.998051)\n",
       " Gray{Float64}(0.998051)  Gray{Float64}(0.998051)     Gray{Float64}(0.998051)\n",
       " Gray{Float64}(0.998051)  Gray{Float64}(0.998051)  …  Gray{Float64}(0.998051)\n",
       " Gray{Float64}(0.998051)  Gray{Float64}(0.998051)     Gray{Float64}(0.998051)\n",
       " Gray{Float64}(0.998051)  Gray{Float64}(0.998051)     Gray{Float64}(0.998051)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using NBInclude\n",
    "@nbinclude(\"src/functions.ipynb\")\n",
    "epoch_to_load =20\n",
    "# Load the model and test set loader\n",
    "dir = \"test/trained_GNN/MNIST_sigmoid_inco\"\n",
    "encoder_μ, encoder_logvar, decoder = load_model_identity(dir, epoch_to_load);\n",
    "\n",
    "\n",
    "batch_size = 64; shuffle = true\n",
    "dataloader = get_test_loader(batch_size, shuffle)\n",
    "(x_batch, y_batch) = first(dataloader)\n",
    "\n",
    "x = reshape(x_batch[:,1], 784,1)\n",
    "\n",
    "μ = encoder_μ(x)\n",
    "logvar = encoder_logvar(x)\n",
    "# Apply reparameterisation trick to sample latent\n",
    "z = μ + randn(Float32, size(logvar)) .* exp.(0.5f0 * logvar)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "35982e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784×500 Matrix{Float32}:\n",
       " -4.79074f-17  -3.18764f-18   1.15231f-18  …  -2.15314f-17  -8.35454f-18\n",
       "  1.93924f-13  -1.31831f-13  -1.1671f-14       1.88386f-13   1.46927f-13\n",
       "  1.72261f-16  -1.36608f-16   1.49686f-16     -4.72904f-17  -3.56617f-17\n",
       "  3.86012f-18   4.15748f-18  -2.77459f-19     -2.14327f-18   4.23553f-19\n",
       " -2.68665f-20   2.06242f-19   1.72418f-19      4.55513f-20  -2.00354f-20\n",
       " -1.54281f-17   1.62059f-17   1.74588f-17  …  -3.20918f-18   7.46922f-18\n",
       "  1.17776f-19   6.88555f-20   9.49247f-20      8.42116f-20   4.11666f-20\n",
       "  3.10197f-20  -1.3666f-20    5.79683f-21      3.49628f-21  -1.36342f-21\n",
       "  4.5031f-19    1.1528f-18    4.94344f-19     -2.22699f-19   6.82695f-19\n",
       "  8.50925f-16   3.46845f-15   2.81665f-15     -2.53351f-15  -3.52455f-17\n",
       "  ⋮                                        ⋱                \n",
       "  0.00391903   -0.00289768    0.0208921    …   0.0409482     0.0231496\n",
       "  0.0112742     0.0028156     0.0151134        0.0287003     0.0216682\n",
       "  0.006198      0.00841768    0.0039179        0.00825732    0.00535425\n",
       "  0.00655454    0.00206012    0.00881549       0.0140838     0.0131687\n",
       " -7.59193f-6   -4.48736f-7    4.6909f-6       -4.83138f-7   -2.23032f-6\n",
       "  7.18792f-14   2.75092f-14   2.3392f-14   …   5.05637f-14   9.07011f-14\n",
       " -7.80977f-14  -1.55212f-14  -4.81154f-14      2.23165f-14   3.03908f-14\n",
       " -3.4119f-12   -2.37021f-12  -2.27085f-12     -1.21842f-12  -2.08632f-13\n",
       " -2.80913f-21   4.91037f-20  -9.3537f-21      -3.30331f-20  -6.57365f-21"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Flux.params(decoder)[9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1f19f729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20-element Vector{Float64}:\n",
       " -0.03784081590906144\n",
       " -2.385492876685151\n",
       "  0.5882618900938914\n",
       "  1.2483459358584463\n",
       "  2.95321293540162\n",
       " -2.0188647898656793\n",
       " -0.9545740562012338\n",
       "  1.3929446623145727\n",
       " -0.6922157976937121\n",
       " -0.3536334064935157\n",
       "  0.2552529042012072\n",
       "  0.18518567013051632\n",
       "  0.7516368735102402\n",
       "  0.8347819242041975\n",
       "  1.0010151657599082\n",
       "  0.22768241383806123\n",
       "  1.2008102346641967\n",
       " -1.132009244298939\n",
       " -0.568888712699821\n",
       "  0.3140137594177993"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z =randn(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "aec433b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500-element Vector{Float32}:\n",
       " 0.49273956\n",
       " 0.6395788\n",
       " 0.88842183\n",
       " 0.58276534\n",
       " 0.6463669\n",
       " 0.61070514\n",
       " 1.1388037\n",
       " 0.86091745\n",
       " 0.5055823\n",
       " 0.7362517\n",
       " ⋮\n",
       " 0.6134886\n",
       " 0.951209\n",
       " 0.9815581\n",
       " 0.5934283\n",
       " 0.8466774\n",
       " 0.9555311\n",
       " 0.5895438\n",
       " 0.865159\n",
       " 1.1374868"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Flux.params(decoder)[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46437f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
