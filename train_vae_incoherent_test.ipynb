{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87388d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "using BSON: @save\n",
    "using BSON: @load\n",
    "using CSV\n",
    "using DataFrames: DataFrame\n",
    "using Flux\n",
    "using Flux: logitbinarycrossentropy, binarycrossentropy, BatchNorm\n",
    "using Flux.Data: DataLoader\n",
    "using Flux: chunk\n",
    "using ImageFiltering\n",
    "using MLDatasets: FashionMNIST\n",
    "using ProgressMeter: Progress, next!\n",
    "using Random\n",
    "using Zygote\n",
    "using MLDatasets\n",
    "using Images\n",
    "using ImageIO\n",
    "using LinearAlgebra\n",
    "using FFTW\n",
    "\n",
    "using NBInclude\n",
    "@nbinclude(\"src/functions.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efe9194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a reshape layer to use in our decoder\n",
    "struct Reshape\n",
    "    shape\n",
    "end\n",
    "Reshape(args...) = Reshape(args)\n",
    "(r::Reshape)(x) = reshape(x, r.shape)\n",
    "Flux.@functor Reshape ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3fbf96e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_vae (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function get_train_loader(batch_size, shuffle::Bool)\n",
    "    # The MNIST training set is made up of 60k 28 by 28 greyscale images\n",
    "    train_x, train_y = MNIST(split=:train)[:]\n",
    "    train_x = 1 .- reshape(train_x, (784, :))\n",
    "    return DataLoader((train_x, train_y), batchsize=batch_size, shuffle=shuffle, partial=false)\n",
    "end\n",
    "\n",
    "function save_model(encoder_μ, encoder_logvar, decoder, W, save_dir::String, epoch::Int)\n",
    "    print(\"Saving model...\")\n",
    "    let encoder_μ = cpu(encoder_μ), encoder_logvar = cpu(encoder_logvar), decoder = cpu(decoder), W = cpu(W)\n",
    "        @save joinpath(save_dir, \"model-$epoch.bson\") encoder_μ encoder_logvar decoder  W\n",
    "    end\n",
    "    println(\"Done\")\n",
    "end\n",
    "\n",
    "function create_vae()\n",
    "    # Define the encoder and decoder networks\n",
    "    encoder_features = Chain(\n",
    "        Dense(784,500, relu),\n",
    "        Dense(500,500, relu)\n",
    "    )\n",
    "    encoder_μ = Chain(encoder_features, Dense(500, 20))\n",
    "    encoder_logvar = Chain(encoder_features, Dense(500, 20))\n",
    "    \n",
    "    decoder = Chain(\n",
    "        Dense(20, 500, relu, bias = false),\n",
    "        Dense(500,500, relu, bias = false),\n",
    "        # Dense(500,784, bias = true)\n",
    "    )\n",
    "    W = randn(784,500)\n",
    "    return encoder_μ, encoder_logvar, decoder, W\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e4fca59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function vae_loss(encoder_μ, encoder_logvar, decoder, W, x, β, λ, F)\n",
    "    batch_size = size(x)[end]\n",
    "    @assert batch_size != 0\n",
    "\n",
    "    # Forward propagate through mean encoder and std encoders\n",
    "    μ = encoder_μ(x)\n",
    "    logvar = encoder_logvar(x)\n",
    "    # Apply reparameterisation trick to sample latent\n",
    "    z = μ + randn(Float32, size(logvar)) .* exp.(0.5f0 * logvar)\n",
    "    # Reconstruct from latent sample\n",
    "\n",
    "    x̂ = W * (decoder(z))  \n",
    "\n",
    "    # cent = abs(sum(x̂))\n",
    "    loss_α(F,A) = maximum(sqrt.(sum((F*A).*(F*A), dims = 2))) + 100*norm(A'*A - I(500),2)^2\n",
    "    α = loss_α(F, W)\n",
    "    \n",
    "    # x_rand1 = (decoder(randn(20,64)))\n",
    "    # # x_rand2 = (decoder(randn(20,64)))\n",
    "    # x_diff = x_rand1 - x̂\n",
    "    # x_diff_norm = sum(x_diff.^2, dims = 1)\n",
    "    # Γ = (F*(x_diff)) .^ 2\n",
    "    # inf_norm_sum = maximum(Γ ./ x_diff_norm) + .001(maximum(abs.(x_rand1)) + abs(maximum(x̂) + minimum(x̂)) )\n",
    "    \n",
    "\n",
    "\n",
    "    # for i in 1:64\n",
    "    #     inf_norm_sum += norm(Γ[:,i], Inf) / x_diff_norm[i]\n",
    "    # end\n",
    "\n",
    "    # Negative reconstruction loss Ε_q[logp_x_z]\n",
    "    logp_x_z = -sum(logitbinarycrossentropy.(x̂, x)) \n",
    "    # KL(qᵩ(z|x)||p(z)) where p(z)=N(0,1) and qᵩ(z|x) models the encoder i.e. reverse KL\n",
    "    # The @. macro makes sure that all operates are elementwise\n",
    "    kl_q_p = 0.5f0 * sum(@. (exp(logvar) + μ^2 - logvar - 1f0)) \n",
    "    # Weight decay regularisation term\n",
    "    reg = λ * sum(x->sum(x.^2), Flux.params(encoder_μ, encoder_logvar, decoder, W))\n",
    "    # We want to maximise the evidence lower bound (ELBO)\n",
    "    elbo = logp_x_z - β .* kl_q_p\n",
    "    # So we minimise the sum of the negative ELBO and a weight penalty\n",
    "    return -elbo + reg + 0.1*norm(x̂ - x, 2)^2 + 10000α\n",
    "end\n",
    "\n",
    "function train(encoder_μ, encoder_logvar, decoder, W, dataloader, num_epochs, λ, β, optimiser, save_dir)\n",
    "    # The training loop for the model\n",
    "    trainable_params = Flux.params(encoder_μ, encoder_logvar, decoder, W)\n",
    "    progress_tracker = Progress(num_epochs, \"Training a epoch done\")\n",
    "\n",
    "    for epoch_num = 1:num_epochs\n",
    "        acc_loss = 0.0\n",
    "        loss = 0\n",
    "        # F_sub = dct(diagm(ones(784)),2)\n",
    "        for (x_batch, y_batch) in dataloader\n",
    "            F_sub = sample_fourier(100, 784)\n",
    "            \n",
    "            # pullback function returns the result (loss) and a pullback operator (back)\n",
    "            loss, back = pullback(trainable_params) do\n",
    "                vae_loss(encoder_μ, encoder_logvar, decoder, W, x_batch, β, λ, F_sub)\n",
    "            end\n",
    "            # Feed the pullback 1 to obtain the gradients and update then model parameters\n",
    "            gradients = back(1f0)\n",
    "            Flux.Optimise.update!(optimiser, trainable_params, gradients)\n",
    "            if isnan(loss)\n",
    "                break\n",
    "            end\n",
    "            acc_loss += loss\n",
    "        end\n",
    "        next!(progress_tracker; showvalues=[(:loss, loss)])\n",
    "        @assert length(dataloader) > 0\n",
    "        avg_loss = acc_loss / length(dataloader)\n",
    "        metrics = DataFrame(epoch=epoch_num, negative_elbo=avg_loss)\n",
    "        # println(metrics)\n",
    "        CSV.write(joinpath(save_dir, \"metrics.csv\"), metrics, header=(epoch_num==1), append=true)\n",
    "        save_model(encoder_μ, encoder_logvar, decoder, W, save_dir, epoch_num)\n",
    "    end\n",
    "    println(\"Training complete!\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "339ecd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[32mTraining a epoch done   5%|██                            |  ETA: 0:39:41\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  1.3092465849116094e13\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done   8%|███                           |  ETA: 0:38:32\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  4.384635184017403e12\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  10%|████                          |  ETA: 0:37:27\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  1.672114909692885e12\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  12%|████                          |  ETA: 0:36:19\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  6.788810061045419e11\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  15%|█████                         |  ETA: 0:35:13\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  2.8355689927968024e11\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  18%|██████                        |  ETA: 0:34:08\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  1.1942139533126756e11\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  20%|███████                       |  ETA: 0:33:04\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  5.002059081147454e10\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  22%|███████                       |  ETA: 0:32:01\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  2.059630010262917e10\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  25%|████████                      |  ETA: 0:30:58\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  8.232465925454814e9\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  28%|█████████                     |  ETA: 0:29:56\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  3.141317229983593e9\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  30%|██████████                    |  ETA: 0:28:53\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  1.1160513312001517e9\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  32%|██████████                    |  ETA: 0:27:50\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  3.548110631246367e8\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  35%|███████████                   |  ETA: 0:26:49\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  9.455392497002943e7\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  38%|████████████                  |  ETA: 0:25:47\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  1.8941920140802372e7\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  40%|█████████████                 |  ETA: 0:24:44\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  2.405596192073841e6\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  42%|█████████████                 |  ETA: 0:23:42\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  182679.2408216791\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  45%|██████████████                |  ETA: 0:22:41\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  43048.227735772605\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  48%|███████████████               |  ETA: 0:21:39\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  38018.033055404485\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  50%|████████████████              |  ETA: 0:20:37\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  35739.02178098305\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  52%|████████████████              |  ETA: 0:19:35\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  32178.477095113674\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving model...Done"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  55%|█████████████████             |  ETA: 0:18:33\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  29302.880524947817\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  58%|██████████████████            |  ETA: 0:17:31\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  27803.85766012768\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  60%|███████████████████           |  ETA: 0:16:29\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  27093.311004330862\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  62%|███████████████████           |  ETA: 0:15:27\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  28136.15584714433\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  65%|████████████████████          |  ETA: 0:14:25\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  27811.142165048248\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  68%|█████████████████████         |  ETA: 0:13:23\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  26568.440955120783\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  70%|██████████████████████        |  ETA: 0:12:21\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  26474.323538713437\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  72%|██████████████████████        |  ETA: 0:11:19\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  26090.76011052048\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  75%|███████████████████████       |  ETA: 0:10:18\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  26255.247139765874\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  78%|████████████████████████      |  ETA: 0:09:16\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  25893.564563009553\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  80%|█████████████████████████     |  ETA: 0:08:14\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  25599.715411894467\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  82%|█████████████████████████     |  ETA: 0:07:12\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  25507.63992454712\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  85%|██████████████████████████    |  ETA: 0:06:11\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  25998.303772211024\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  88%|███████████████████████████   |  ETA: 0:05:09\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  26697.042364177374\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  90%|████████████████████████████  |  ETA: 0:04:07\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  26146.513268748073\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  92%|████████████████████████████  |  ETA: 0:03:05\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  26068.6216221265\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  95%|█████████████████████████████ |  ETA: 0:02:03\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  26201.432185708058\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  98%|██████████████████████████████|  ETA: 0:01:02\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  26838.69821468214\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done 100%|██████████████████████████████| Time: 0:41:09\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  26297.0811641319\u001b[39m\u001b[K\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "shuffle_data = true\n",
    "η = 0.001\n",
    "β = 1f0\n",
    "λ = 0.01f0\n",
    "num_epochs = 40\n",
    "save_dir = \"test/trained_GNN/MNIST_relu\"\n",
    "# Define the model and create our data loader\n",
    "dataloader = get_train_loader(batch_size, shuffle_data)\n",
    "encoder_μ, encoder_logvar, decoder, W= create_vae()\n",
    "train(encoder_μ, encoder_logvar, decoder, W, dataloader, num_epochs, λ, β, ADAM(η), save_dir)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26330dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "visualise (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function get_test_loader(batch_size, shuffle::Bool)\n",
    "    # The FashionMNIST test set is made up of 10k 28 by 28 greyscale images\n",
    "    test_x, test_y = MNIST(split=:test)[:]\n",
    "    test_x = 1 .- reshape(test_x, (784, :))\n",
    "    return DataLoader((test_x, test_y), batchsize=batch_size, shuffle=shuffle)\n",
    "end\n",
    "\n",
    "function save_to_images(x_batch, save_dir::String, prefix::String, num_images::Int64)\n",
    "    @assert num_images <= size(x_batch)[2]\n",
    "    for i=1:num_images\n",
    "        save(joinpath(save_dir, \"$prefix-$i.png\"), colorview(Gray, reshape(x_batch[:, i], 28,28)' ))\n",
    "    end\n",
    "end\n",
    "\n",
    "function reconstruct_images(encoder_μ, encoder_logvar, decoder, x)\n",
    "    # Forward propagate through mean encoder and std encoders\n",
    "    μ = encoder_μ(x)\n",
    "    logvar = encoder_logvar(x)\n",
    "    # Apply reparameterisation trick to sample latent\n",
    "    z = μ + randn(Float32, size(logvar)) .* exp.(0.5f0 * logvar)\n",
    "    # Reconstruct from latent sample\n",
    "\n",
    "    x̂ = sigmoid(decoder(z))\n",
    "    return clamp.(x̂, 0 ,1)\n",
    "end\n",
    "\n",
    "function load_model_identity(load_dir::String, epoch::Int)\n",
    "    print(\"Loading model...\")\n",
    "    @load joinpath(load_dir, \"model-$epoch.bson\") encoder_μ encoder_logvar decoder W\n",
    "    println(\"Done\")\n",
    "    return encoder_μ, encoder_logvar, decoder, W\n",
    "end\n",
    "\n",
    "function visualise()\n",
    "    # Define some parameters\n",
    "    batch_size = 1\n",
    "    shuffle = true\n",
    "    num_images = 1\n",
    "    epoch_to_load = 20\n",
    "    # Load the model and test set loader\n",
    "    dir = \"test/trained_GNN/MNIST_sigmoid_inco\"\n",
    "    encoder_μ, encoder_logvar, decoder= load_model_identity(dir, epoch_to_load)\n",
    "    dataloader = get_test_loader(batch_size, shuffle)\n",
    "    # Reconstruct and save some images\n",
    "    for (x_batch, y_batch) in dataloader\n",
    "        save_to_images(x_batch, dir, \"test-image\", num_images)\n",
    "        x̂_batch = reconstruct_images(encoder_μ, encoder_logvar, decoder, x_batch)\n",
    "        print(size(x_batch))\n",
    "        save_to_images(x̂_batch, dir, \"reconstruction\", num_images)\n",
    "        break\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf26eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c4dff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "load(\"test/trained_GNN/MNIST_sigmoid_inco/reconstruction-1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd198a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "load(\"test/trained_GNN/MNIST_sigmoid_inco/test-image-1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0f22c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All function imported\n",
      "Loading model...Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Chain(Chain(Dense(784 => 500, relu), Dense(500 => 500, relu)), Dense(500 => 20)), Chain(Chain(Dense(784 => 500, relu), Dense(500 => 500, relu)), Dense(500 => 20)), Chain(Dense(20 => 500, relu; bias=false), Dense(500 => 500, relu; bias=false)), [0.005073787634532151 0.019671017698285245 … 0.005401578961626009 0.03505487141940171; -0.02598047421298229 -0.0008783655326210292 … 0.012016930845491403 0.006034566162204524; … ; -0.002879707078845804 -0.016841959331383664 … 1.1762516885401466e-5 -0.00930029475700759; -0.007068885192699047 0.007394328279686085 … 0.0017658044990063785 -0.03774220016757633])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using NBInclude\n",
    "@nbinclude(\"src/functions.ipynb\")\n",
    "epoch_to_load =20\n",
    "# Load the model and test set loader\n",
    "dir = \"test/trained_GNN/MNIST_relu\"\n",
    "encoder_μ, encoder_logvar, decoder, W = load_model_identity(dir, epoch_to_load);\n",
    "\n",
    "\n",
    "# batch_size = 64; shuffle = true\n",
    "# dataloader = get_test_loader(batch_size, shuffle)\n",
    "# (x_batch, y_batch) = first(dataloader)\n",
    "\n",
    "# # x = reshape(x_batch[:,1], 784,1)\n",
    "\n",
    "# μ = encoder_μ(x_batch)\n",
    "# logvar = encoder_logvar(x_batch)\n",
    "# # Apply reparameterisation trick to sample latent\n",
    "# z = μ + randn(Float32, size(logvar)) .* exp.(0.5f0 * logvar);\n",
    "\n",
    "\n",
    "# z1 = z[:,1]\n",
    "# z2 = z[:,2]\n",
    "# β = 1\n",
    "# colorview(Gray,reshape(sigmoid(decoder(β * z2 + (1-β) *z1))[:,1], 28,28)')\n",
    "# colorview(Gray,reshape(sigmoid(decoder(randn(20)))[:,1], 28,28)')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a792e5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "F = dct(diagm(ones(784)),2);\n",
    "\n",
    "x_rand1 = sigmoid(decoder(randn(20,100)))\n",
    "x_rand2 = sigmoid(decoder(randn(20,100)))\n",
    "x_diff = x_rand1 - x_rand2\n",
    "x_diff_norm = sum(x_diff.^2, dims = 1)\n",
    "Γ = (F*(x_diff)) .^ 2\n",
    "\n",
    "\n",
    "maximum(Γ ./ x_diff_norm)\n",
    "\n",
    "# inf_norm_sum = 0\n",
    "\n",
    "# for i in 1:64\n",
    "#     inf_norm_sum += norm(Γ[:,i], Inf) / x_diff_norm[i]\n",
    "# end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d348164f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rand1 = sigmoid(decoder(randn(20,1)))\n",
    "x_rand2 = sigmoid(decoder(randn(20,1)))\n",
    "x_diff = x_rand1 - x_rand2\n",
    "colorview(Gray,reshape(x_diff, 28,28)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732c43e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm(randn(2,2), Inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbad39e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum(abs(randn(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe87c62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Γ[:,2] / x_diff_norm[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05921a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
