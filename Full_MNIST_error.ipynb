{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: using JLD.@load in module Main conflicts with an existing identifier.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using NBInclude\n",
    "@nbinclude(\"functions.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup\n",
    "x_dim = 784\n",
    "m = 200\n",
    "k = 20\n",
    "epoch_to_load = 20 # Load the model and test set loader\n",
    "tolerance = 1e-7; max_iter = 2000; out_toggle = 0\n",
    "β_list = 0:.1:1\n",
    "trials = 20\n",
    "opt = Flux.Optimise.ADAM(.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, decoder = load_model(\"MNIST\", epoch_to_load)\n",
    "B = randn(784, 500)/sqrt(784)\n",
    "z = randn(k) # ground code vector\n",
    "α_list = []\n",
    "F = dct(diagm(ones(x_dim)),2)\n",
    "for β in β_list\n",
    "    push!(α_list, subspace_incoherence(F, β * Flux.params(decoder)[3] + (1-β)*B) )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "recovery_error_matrix = zeros(trials)\n",
    "recon_error_matrix = zeros(trials)\n",
    "for β in β_list\n",
    "    recovery_error_list = []\n",
    "    recon_error_list = []\n",
    "    G = Chain(\n",
    "        Dense(20, 500, relu, bias = false; init =(out,in) -> Flux.params(decoder)[1]),\n",
    "        Dense(500, 500, relu, bias = false; init =(out,in) -> Flux.params(decoder)[2]),\n",
    "        Dense(500, 784, identity, bias = false; init =(out,in) -> β * Flux.params(decoder)[3] + (1-β)*B),\n",
    "    )   #setup the generative network \n",
    "\n",
    "\n",
    "    for trials in 1:trials\n",
    "        F_sub = sample_fourier(m, x_dim)  # subsampling DCT for measurement matrix\n",
    "        F_sub = F_sub * sqrt(x_dim)/sqrt(m) #normalization          \n",
    "        y = F_sub * G(z) # measurement vector using subsampled DCT matrix\n",
    "  \n",
    "        z_est = randn(k) #initialization for algorithm\n",
    "        z_est = estimated_code(opt, G, y, F_sub, z_est; max_iter, tolerance, out_toggle)  # run a optimizer to solve the least squares problem\n",
    "\n",
    "        push!(recovery_error_list, relative_error(z, z_est))    \n",
    "        push!(recon_error_list, relative_error(G(z), G(z_est)))\n",
    "    end\n",
    "\n",
    "    recovery_error_matrix =  hcat(recovery_error_matrix, recovery_error_list)\n",
    "    recon_error_matrix = hcat(recon_error_matrix, recon_error_list)\n",
    "end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11-element Vector{Any}:\n",
       " 0.8467596642220849\n",
       " 0.9311394555706298\n",
       " 0.9646827042585921\n",
       " 0.9774385492232273\n",
       " 0.983521608262825\n",
       " 0.9859371517903763\n",
       " 0.9865932104842539\n",
       " 0.986459116125491\n",
       " 0.9853124576955354\n",
       " 0.9829007370386266\n",
       " 0.9787944574668505"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cs = palette([:red,  :orange, :green, :blue, :Indigo], 1000)\n",
    "\n",
    "\n",
    "log_recovery_error_matrix = log10.(recovery_error_matrix[:, 2:end])\n",
    "average_recov = mean(log_recovery_error_matrix, dims=1)'\n",
    "std_recov = std(log_recovery_error_matrix, dims=1)'\n",
    "plot(α_list, average_recov + std_recov, fillrange =  average_recov - std_recov, fillalpha = .2, c = cs[400], label = false,linecolor = invisible())\n",
    "scatter!(kron(α_list',ones(trials,1))[:], log_recovery_error_matrix[:], label =:false)\n",
    "p1 = plot!(α_list, average_recov, xlabel = \"incoherence upper bound\", ylabel = \"relative recovery error\", linewidth = 2, color = cs[1000], label =false)\n",
    "yticks = [-6:2:0;]\n",
    "yticks!(yticks, [L\"10^{%$y}\" for y in yticks])\n",
    "\n",
    "\n",
    "\n",
    "log_recon_error_matrix = log10.(recon_error_matrix[:, 2:end])\n",
    "average_recon = mean(log_recon_error_matrix, dims=1)'\n",
    "std_recon = std(log_recon_error_matrix, dims=1)'\n",
    "plot(α_list, average_recon + std_recon, fillrange = average_recon - std_recon, fillalpha = .2, c = cs[400], label = false, linecolor = invisible())\n",
    "scatter!(kron(α_list',ones(trials,1))[:], log_recon_error_matrix[:], label =:false)\n",
    "p2 = plot!(α_list, average_recon, xlabel = \"incoherence upper bound\", ylabel = \"relative reconstruction error\", linewidth = 2, color = cs[1000], label =false )\n",
    "yticks = [-8:2:0;]\n",
    "yticks!(yticks, [L\"10^{%$y}\" for y in yticks])\n",
    "plot(p1,p2,layout = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7985957062499249"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "savefig(\"figures/Full_MNIST_error.pdf\")\n",
    "save(\"save_data/Full_MNIST_error.jld\", \"recovery error\", recovery_error_matrix, \"reconstruction error\", recon_error_matrix, \"α_list\", α_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
