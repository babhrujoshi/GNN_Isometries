{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87388d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "using BSON: @save\n",
    "using BSON: @load\n",
    "using CSV\n",
    "using DataFrames: DataFrame\n",
    "using Flux\n",
    "using Flux: logitbinarycrossentropy, binarycrossentropy\n",
    "using Flux.Data: DataLoader\n",
    "using Flux: chunk\n",
    "using ImageFiltering\n",
    "using MLDatasets: FashionMNIST\n",
    "using ProgressMeter: Progress, next!\n",
    "using Random\n",
    "using Zygote\n",
    "using MLDatasets\n",
    "using Images\n",
    "using ImageIO\n",
    "using LinearAlgebra\n",
    "using FFTW\n",
    "using Plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0efe9194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a reshape layer to use in our decoder\n",
    "struct Reshape\n",
    "    shape\n",
    "end\n",
    "Reshape(args...) = Reshape(args)\n",
    "(r::Reshape)(x) = reshape(x, r.shape)\n",
    "Flux.@functor Reshape ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeffbdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function active_weights(W,z)\n",
    "#     return diagm(Int.((W*z) .> 0))*W\n",
    "# end\n",
    "\n",
    "\n",
    "# function HingeLoss_0(y; slope=-10, eps = .1)\n",
    "#     return sum((max.(0,slope .* y .- eps .* slope)).^2)/size(y,2)\n",
    "# end\n",
    "\n",
    "# function HingeLoss_1(y; slope = 10, eps = .1)\n",
    "#     return sum((max.(0, slope .* y .- slope .* (1+eps) )).^2 )/size(y,2)\n",
    "# end\n",
    "\n",
    "# function Hinge_0_1(y;slope = 1)\n",
    "#     max.(-1 .*max.(0, abs.(y) ) .+ 1, 0)\n",
    "# end\n",
    "\n",
    "# function BCE_own(ŷ, y; ϵ =1e-5)\n",
    "#     sum(@.(-y * log(Hinge_0_1_v2(ŷ) +ϵ) - (1 - y) * log(Hinge_0_1(ŷ) + ϵ)))/size(y,2)\n",
    "# end\n",
    "\n",
    "\n",
    "# function Hinge_0_1_v2(y;slope = 1)\n",
    "#     max.(-1 .* max.(0, abs.(y - 1 )) + 1 , 0)\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3fbf96e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165.61993400560496"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function get_train_loader(batch_size, shuffle::Bool)\n",
    "    # The MNIST training set is made up of 60k 28 by 28 greyscale images\n",
    "    train_x, train_y = MNIST.traindata(Float32)\n",
    "    train_x = 1 .- reshape(train_x, (784, :))\n",
    "    return DataLoader((train_x, train_y), batchsize=batch_size, shuffle=shuffle, partial=false)\n",
    "end\n",
    "\n",
    "function save_model(encoder_μ, encoder_logvar, W1, W2, W3, Q, save_dir::String, epoch::Int)\n",
    "    print(\"Saving model...\")\n",
    "    let encoder_μ = cpu(encoder_μ), encoder_logvar = cpu(encoder_logvar), W1 = cpu(W1), W2 = cpu(W2), W3 = cpu(W3), Q = cpu(Q)\n",
    "        @save joinpath(save_dir, \"model-$epoch.bson\") encoder_μ encoder_logvar W1 W2 W3 Q\n",
    "    end\n",
    "    println(\"Done\")\n",
    "end\n",
    "\n",
    "function create_vae()\n",
    "    # Define the encoder and decoder networks\n",
    "    encoder_features = Chain(\n",
    "        Dense(784,500, relu),\n",
    "        Dense(500,500, relu)\n",
    "    )\n",
    "    encoder_μ = Chain(encoder_features, Dense(500, 20))\n",
    "    encoder_logvar = Chain(encoder_features, Dense(500, 20))\n",
    "\n",
    "    W1 = randn(500,20)\n",
    "    W2 = randn(500,500)\n",
    "    W3 = randn(500,500)\n",
    "    Q = randn(784,500)\n",
    "\n",
    "    return encoder_μ, encoder_logvar, W1, W2, W3, Q\n",
    "end\n",
    "\n",
    "\n",
    "# function sigmoid_scaled(x)\n",
    "#     α = (exp(1) + exp(-1))/(exp(1) - exp(-1))\n",
    "#     return α * (exp(x) - exp(-x))/(exp(x) + exp(-x)) \n",
    "# end\n",
    "\n",
    "# function BCE_own(ŷ, y; ϵ =1e-5)\n",
    "#     α = (exp(1) + exp(-1))/(exp(1) - exp(-1))\n",
    "#     sum(@.(-y * log( α + sigmoid_scaled(ŷ)  +ϵ) - (1 - y) * log(1 - sigmoid(ŷ)/sigmoid(1) + ϵ)))/size(y,2)\n",
    "# end\n",
    "# y = randn(5)\n",
    "# ŷ = randn(5)\n",
    "# α = (exp(1) + exp(-1))/(exp(1) - exp(-1))\n",
    "\n",
    "\n",
    "function sig_shifted_v2(x)\n",
    "    M = 0.375261028309015\n",
    "    X = 0.624697168346519\n",
    "    α = X/0.5\n",
    "    sig(x) = exp(-x^2)*tanh(x)\n",
    "    return @.(sig(α*(x-.5))/(2M)  + 1/2)\n",
    "end\n",
    "\n",
    "function sig_shifted(x)\n",
    "    M = 1.04187855854289\n",
    "    X = 1.01570942991227\n",
    "    α = X/0.25\n",
    "    sig(x) = (exp(-x^2)+.99) * tanh(x)\n",
    "    return @.(sig(α*(x-.5))/(2M)  + 1/2)\n",
    "end\n",
    "\n",
    "function sig_shifted_v3(x)\n",
    "    M = 0.321140015957206\n",
    "    X = 0.58703932739034\n",
    "    α = X/0.5\n",
    "    sig(x) = (exp(-x^2) - .1)*tanh(x)\n",
    "    return @.(sig(α*(x-.5))/(2M)  + 1/2)\n",
    "end\n",
    "\n",
    "function BCE_own(x̂,x)\n",
    "    return sum( @.( -(1-x)*log(1 - (sigmoid(abs(1-x̂)) .- .5) * min((abs(x̂))^1.01, 1) + 1e-5)  - x*( log(1 - (sigmoid(abs(1-x̂)) .- .5)* min((abs(1-x̂))^1.01, 1)  + 1e-5) ) ) )/784\n",
    "end\n",
    "\n",
    "function BCE_own(x̂)\n",
    "    invgaus(x) =  @.(-exp(-(x)^2) +1)\n",
    "    return sum( @.( - log(1 - invgaus( max( abs(.5-x̂) -.5 , .5 ) -.5 ) + 1e-5)  ) )/size(x̂,2)\n",
    "end\n",
    "\n",
    "function  logit_BCE(x̂,x) \n",
    "    return sum(@.(- x * log( sigmoid(x̂) + 1e-5) - (1-x)* log( 1 - sigmoid(x̂) + 1e-5))) / size(x,2)\n",
    "end\n",
    "\n",
    "function  logit_BCE_shifted(x̂,x) \n",
    "    return sum(@.(- x * log( sig_shifted(x̂) + 1e-4) - (1-x)* log( 1 - sig_shifted(x̂) + 1e-4))) / size(x,2)\n",
    "end\n",
    "\n",
    "BCE_own(randn(700))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c57b00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCE_own (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BCE_own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e4fca59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function vae_loss(encoder_μ, encoder_logvar, W1, W2, W3, Q, x, β, λ, F)\n",
    "    batch_size = size(x)[end]\n",
    "    @assert batch_size != 0\n",
    "\n",
    "    # Forward propagate through mean encoder and std encoders\n",
    "    μ = encoder_μ(x)\n",
    "    logvar = encoder_logvar(x)\n",
    "    # Apply reparameterisation trick to sample latent\n",
    "    z = μ + randn(Float32, size(logvar)) .* exp.(0.5f0 * logvar)\n",
    "    # Reconstruct from latent sample\n",
    "    x̂ = Q*relu(W2*relu(W1*z))\n",
    "\n",
    "    # Negative reconstruction loss Ε_q[logp_x_z]\n",
    "    logp_x_z = sum(logit_BCE.(x̂, x))\n",
    "    loss_mse = sum(BCE_own.(x̂))\n",
    "\n",
    "    # KL(qᵩ(z|x)||p(z)) where p(z)=N(0,1) and qᵩ(z|x) models the encoder i.e. reverse KL\n",
    "    # The @. macro makes sure that all operates are elementwise\n",
    "    kl_q_p = 0.5f0 * sum(@. (exp(logvar) + μ^2 - logvar - 1f0)) \n",
    "    # Weight decay regularisation term\n",
    "    reg = λ * sum(x->sum(x.^2), Flux.params(encoder_μ, encoder_logvar, W1, W2, Q))\n",
    "    # We want to maximise the evidence lower bound (ELBO)\n",
    "    elbo = - β .* kl_q_p\n",
    "    # So we minimise the sum of the negative ELBO and a weight penalty\n",
    "\n",
    "    # println(\"$(loss_mse)     $(elbo)        $(logp_x_z)\")\n",
    "    return -elbo + reg + loss_mse + logp_x_z #+ 10*norm(x̂, Inf) #+ 7000 * α \n",
    "end\n",
    "\n",
    "function train(encoder_μ, encoder_logvar, W1, W2, W3, Q, dataloader, num_epochs, λ, β, optimiser, save_dir)\n",
    "    # The training loop for the model\n",
    "    trainable_params = Flux.params(encoder_μ, encoder_logvar, W1, W2, W3, Q)\n",
    "    progress_tracker = Progress(num_epochs, \"Training a epoch done\")\n",
    "    F = dct(diagm(ones(784)),2);\n",
    "\n",
    "    for epoch_num = 31:num_epochs\n",
    "        acc_loss = 0.0\n",
    "        loss = 0\n",
    "        for (x_batch, y_batch) in dataloader\n",
    "            # pullback function returns the result (loss) and a pullback operator (back)\n",
    "            loss, back = pullback(trainable_params) do\n",
    "                vae_loss(encoder_μ, encoder_logvar, W1, W2, W3, Q, x_batch, β, λ, F)\n",
    "            end\n",
    "            # Feed the pullback 1 to obtain the gradients and update then model parameters\n",
    "            gradients = back(1f0)\n",
    "            Flux.Optimise.update!(optimiser, trainable_params, gradients)\n",
    "            if isnan(loss)\n",
    "                break\n",
    "            end\n",
    "            acc_loss += loss\n",
    "        end\n",
    "        next!(progress_tracker; showvalues=[(:loss, loss)])\n",
    "        @assert length(dataloader) > 0\n",
    "        avg_loss = acc_loss / length(dataloader)\n",
    "        metrics = DataFrame(epoch=epoch_num, negative_elbo=avg_loss)\n",
    "        println(metrics)\n",
    "        CSV.write(joinpath(save_dir, \"metrics.csv\"), metrics, header=(epoch_num==1), append=true)\n",
    "        save_model(encoder_μ, encoder_logvar, W1, W2, W3, Q, save_dir, epoch_num)\n",
    "    end\n",
    "    println(\"Training complete!\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "339ecd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1×2 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m epoch \u001b[0m\u001b[1m negative_elbo \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Float64       \u001b[0m\n",
      "─────┼──────────────────────\n",
      "   1 │    31        21497.6\n",
      "Saving model...Done"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[32mTraining a epoch done   4%|██                            |  ETA: 0:22:48\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  16337.696909104288\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m1×2 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m epoch \u001b[0m\u001b[1m negative_elbo \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Float64       \u001b[0m\n",
      "─────┼──────────────────────\n",
      "   1 │    32        16650.1\n",
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done   6%|██                            |  ETA: 0:22:09\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  16658.03465457321\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1×2 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m epoch \u001b[0m\u001b[1m negative_elbo \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Float64       \u001b[0m\n",
      "─────┼──────────────────────\n",
      "   1 │    33        16384.7\n",
      "Saving model...Done"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done   8%|███                           |  ETA: 0:21:35\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  15866.274997266866\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m1×2 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m epoch \u001b[0m\u001b[1m negative_elbo \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Float64       \u001b[0m\n",
      "─────┼──────────────────────\n",
      "   1 │    34        16277.7\n",
      "Saving model...Done"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  10%|████                          |  ETA: 0:21:04\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  15810.826452337675\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m1×2 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m epoch \u001b[0m\u001b[1m negative_elbo \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Float64       \u001b[0m\n",
      "─────┼──────────────────────\n",
      "   1 │    35        16206.2\n",
      "Saving model...Done"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  12%|████                          |  ETA: 0:20:34\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  16103.044697324667\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m1×2 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m epoch \u001b[0m\u001b[1m negative_elbo \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Float64       \u001b[0m\n",
      "─────┼──────────────────────\n",
      "   1 │    36        16153.2\n",
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  14%|█████                         |  ETA: 0:20:05\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  16200.71570267958\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1×2 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m epoch \u001b[0m\u001b[1m negative_elbo \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Float64       \u001b[0m\n",
      "─────┼──────────────────────\n",
      "   1 │    37        16112.1\n",
      "Saving model...Done"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  16%|█████                         |  ETA: 0:19:36\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  15988.448143327056\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m1×2 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m epoch \u001b[0m\u001b[1m negative_elbo \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Float64       \u001b[0m\n",
      "─────┼──────────────────────\n",
      "   1 │    38        16077.9\n",
      "Saving model...Done"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  18%|██████                        |  ETA: 0:19:07\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  16041.955736877357\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m1×2 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m epoch \u001b[0m\u001b[1m negative_elbo \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Float64       \u001b[0m\n",
      "─────┼──────────────────────\n",
      "   1 │    39        16046.4\n",
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  20%|███████                       |  ETA: 0:18:39\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  16078.40173793346\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1×2 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m epoch \u001b[0m\u001b[1m negative_elbo \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Float64       \u001b[0m\n",
      "─────┼──────────────────────\n",
      "   1 │    40        16016.5\n",
      "Saving model...Done"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  22%|███████                       |  ETA: 0:18:10\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  15712.956710186558\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m1×2 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m epoch \u001b[0m\u001b[1m negative_elbo \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Float64       \u001b[0m\n",
      "─────┼──────────────────────\n",
      "   1 │    41        15993.3\n",
      "Saving model...Done"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  24%|████████                      |  ETA: 0:17:42\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  16028.408103013242\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m1×2 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m epoch \u001b[0m\u001b[1m negative_elbo \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Float64       \u001b[0m\n",
      "─────┼──────────────────────\n",
      "   1 │    42        15972.6\n",
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  26%|████████                      |  ETA: 0:17:14\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  16114.5485906472\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1×2 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m epoch \u001b[0m\u001b[1m negative_elbo \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Float64       \u001b[0m\n",
      "─────┼──────────────────────\n",
      "   1 │    43        15954.5\n",
      "Saving model...Done"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  28%|█████████                     |  ETA: 0:16:48\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  15813.415718890908\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m1×2 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m epoch \u001b[0m\u001b[1m negative_elbo \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Float64       \u001b[0m\n",
      "─────┼──────────────────────\n",
      "   1 │    44        15935.1\n",
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  30%|██████████                    |  ETA: 0:16:20\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  15610.941476139913\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1×2 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m epoch \u001b[0m\u001b[1m negative_elbo \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Float64       \u001b[0m\n",
      "─────┼──────────────────────\n",
      "   1 │    45        15921.9\n",
      "Saving model...Done"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  32%|██████████                    |  ETA: 0:15:53\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  16168.465600256672\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m1×2 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m epoch \u001b[0m\u001b[1m negative_elbo \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Float64       \u001b[0m\n",
      "─────┼──────────────────────\n",
      "   1 │    46        15907.9\n",
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  34%|███████████                   |  ETA: 0:15:25\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  16203.86373586085\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1×2 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m epoch \u001b[0m\u001b[1m negative_elbo \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Float64       \u001b[0m\n",
      "─────┼──────────────────────\n",
      "   1 │    47        15891.1\n",
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  36%|███████████                   |  ETA: 0:14:56\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  16047.78205315386\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1×2 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m epoch \u001b[0m\u001b[1m negative_elbo \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Float64       \u001b[0m\n",
      "─────┼──────────────────────\n",
      "   1 │    48        15883.4\n",
      "Saving model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  38%|████████████                  |  ETA: 0:14:28\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  16005.347871418668\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1×2 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m epoch \u001b[0m\u001b[1m negative_elbo \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Float64       \u001b[0m\n",
      "─────┼──────────────────────\n",
      "   1 │    49        15867.6\n",
      "Saving model...Done"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  40%|█████████████                 |  ETA: 0:14:01\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  15952.455670639933\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m1×2 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m epoch \u001b[0m\u001b[1m negative_elbo \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Float64       \u001b[0m\n",
      "─────┼──────────────────────\n",
      "   1 │    50        15857.4\n",
      "Saving model...Done\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "shuffle_data = true\n",
    "η = 0.001\n",
    "β = 1f0\n",
    "λ = 0.01f0\n",
    "\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "save_dir = \"trained_GNN/MNIST_unenforced_v2\"\n",
    "# Define the model and create our data loader\n",
    "dataloader = get_train_loader(batch_size, shuffle_data)\n",
    "# encoder_μ, encoder_logvar, W1, W2, W3, Q  = create_vae()\n",
    "train(encoder_μ, encoder_logvar, W1, W2, W3, Q, dataloader, num_epochs, λ, β, ADAM(η, (0.9,0.8)), save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26330dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "visualise (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function get_test_loader(batch_size, shuffle::Bool)\n",
    "    # The FashionMNIST test set is made up of 10k 28 by 28 greyscale images\n",
    "    test_x, test_y = MNIST.testdata(Float32)\n",
    "    test_x = 1 .- reshape(test_x, (784, :))\n",
    "    return DataLoader((test_x, test_y), batchsize=batch_size, shuffle=shuffle)\n",
    "end\n",
    "\n",
    "function save_to_images(x_batch, save_dir::String, prefix::String, num_images::Int64)\n",
    "    @assert num_images <= size(x_batch)[2]\n",
    "    for i=1:num_images\n",
    "        save(joinpath(save_dir, \"$prefix-$i.png\"), colorview(Gray, reshape(x_batch[:, i], 28,28)' ))\n",
    "    end\n",
    "end\n",
    "\n",
    "function reconstruct_images(encoder_μ, encoder_logvar, W1, W2, W3, Q, x)\n",
    "    # Forward propagate through mean encoder and std encoders\n",
    "    μ = encoder_μ(x)\n",
    "    logvar = encoder_logvar(x)\n",
    "    # Apply reparameterisation trick to sample latent\n",
    "    z = μ + randn(Float32, size(logvar)) .* exp.(0.5f0 * logvar)\n",
    "    # Reconstruct from latent sample\n",
    "    x̂ = Q*relu(W2*relu(W1*z))\n",
    "    return clamp.(x̂, 0 ,1)\n",
    "end\n",
    "\n",
    "function load_model_identity(load_dir::String, epoch::Int)\n",
    "    print(\"Loading model...\")\n",
    "    @load joinpath(load_dir, \"model-$epoch.bson\") encoder_μ encoder_logvar W1 W2 W3 Q\n",
    "    println(\"Done\")\n",
    "    return encoder_μ, encoder_logvar, W1, W2, W3, Q\n",
    "end\n",
    "\n",
    "function visualise()\n",
    "    # Define some parameters\n",
    "    batch_size = 64\n",
    "    shuffle = true\n",
    "    num_images = 20\n",
    "    epoch_to_load = 20\n",
    "    # Load the model and test set loader\n",
    "    dir = \"trained_GNN/MNIST_unenforced_v2\"\n",
    "    encoder_μ, encoder_logvar, W1, W2, W3, Q = load_model_identity(dir, epoch_to_load)\n",
    "    dataloader = get_test_loader(batch_size, shuffle)\n",
    "    # Reconstruct and save some images\n",
    "    for (x_batch, y_batch) in dataloader\n",
    "        save_to_images(x_batch, dir, \"test-image\", num_images)\n",
    "        x̂_batch = reconstruct_images(encoder_μ, encoder_logvar, W1, W2, W3, Q, x_batch)\n",
    "        save_to_images(x̂_batch, dir, \"reconstruction\", num_images)\n",
    "        break\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eaf26eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "visualise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04c4dff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAY1JREFUaAW9wTFvjAEABuBHvINEhMQqFrqwmc1EgqmDwcrQpkMHq8UmQlJDB6uIprGw9AfwAwy6SP2TpubefXf33ZX3eXKiK8qiLMqiLMqiLMqiLMqiLMqiLMqiLMrijJ7jg2m38Mu0KIuyKIsVvcQrsx3iN9acFmVRFmWxgnPGWTMtyqIsymIJX7BunOs4xnmnRVmURVmM9AAHxtnBlmFRFmVRFiM8xoFxtrFltiiLsiiLEb4Z5yHemi/KoizKYoGbxrmIfYtFWZRFWczxB0fGeYcLFouyKIuymGPTeO/xzGJRFmVRFjNs4MB4h8aJsiiLshiwi13LOcYTvME1s0VZlEVZDNgw2w0cGbaHPTzFNu6YFmVRFmWxpCOLfcQnbGLHaVEWZVEWE376N27jnmlRFmVRFhOuOrtH+GpYlEVZlMWEy1a3jn3zRVmURVlMuGQ59/EZV4wTZVEWZTHgBHfxw7DXeGE1URZlURYzfPd/RFmURVmURVmURVmURVmURVmURVmURVmURVmURdlf5KwoD23RXvEAAAAASUVORK5CYII=",
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAY1JREFUaAW9wTFvjAEABuBHvINEhMQqFrqwmc1EgqmDwcrQpkMHq8UmQlJDB6uIprGw9AfwAwy6SP2TpubefXf33ZX3eXKiK8qiLMqiLMqiLMqiLMqiLMqiLMqiLMrijJ7jg2m38Mu0KIuyKIsVvcQrsx3iN9acFmVRFmWxgnPGWTMtyqIsymIJX7BunOs4xnmnRVmURVmM9AAHxtnBlmFRFmVRFiM8xoFxtrFltiiLsiiLEb4Z5yHemi/KoizKYoGbxrmIfYtFWZRFWczxB0fGeYcLFouyKIuymGPTeO/xzGJRFmVRFjNs4MB4h8aJsiiLshiwi13LOcYTvME1s0VZlEVZDNgw2w0cGbaHPTzFNu6YFmVRFmWxpCOLfcQnbGLHaVEWZVEWE376N27jnmlRFmVRFhOuOrtH+GpYlEVZlMWEy1a3jn3zRVmURVlMuGQ59/EZV4wTZVEWZTHgBHfxw7DXeGE1URZlURYzfPd/RFmURVmURVmURVmURVmURVmURVmURVmURVmURdlf5KwoD23RXvEAAAAASUVORK5C\">"
      ],
      "text/plain": [
       "28×28 Array{Gray{N0f8},2} with eltype Gray{N0f8}:\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " ⋮                                 ⋱                   \n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "load(\"trained_GNN/MNIST_unenforced_v2/reconstruction-3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecd198a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAhlJREFUaAW9wT2olQUABuDn4BvEsaVUIkQSalIityBoCKLFaA2icLKEoCVoK6KoViGKWlsabMihoAiSomyQshJaolTESZQKoh/zNHzD5Zx77rnf1XifJzNdURZlURZlURZlURZlURZlURb/s3/wu8HNmJoXZVEWZXGdLuBPgy9w0uAiPjJ4Cm+bF2VRFmWxBX/jNZzBCVy22jbrRVmURVlswZt42eZux1t4xHpRFmVRFiN9h9etdj8ewNPYa7koi7Ioi5GO45LlnsVz2IGp1aIsyqIsRngHr5r3JF7BDkwxMU6URVmUxQj3WO9LHMXz2G68KIuyKIsRzuKqeT/jKD7GMewzTpRFWZTFCI/jE7xrMMMEM/yIe/EBDtpclEVZlMVIL+EKvsUFg4nBv3gBB7DbalEWZVEWI+3FcVzEr3gC32BicBqH8KnVoizKoixG+hpfWXMQ53DZms/xGR60sSiLsiiLBTO8j+/xHs4bXMM1q13FEZzAHZaLsiiLslhwBY9ZbYaJeTNMsBO32ViURVmUxYLDNjex3sTgB/yE/ZaLsiiLslhwyo25G3tsLMqiLMpiwaP4EGeNtw/34YjBNhuLsiiLsljwBl7Eb/gFx6w5iTN4GHcaPIM9uNU4URZlURZL7MIu3IWHrPkDf+EW3OT6RFmURVlswRRTNybKoizKoizKoizKoizKoizKoizKoizKoizKoizK/gO5nU72pg9JvwAAAABJRU5ErkJggg==",
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAhlJREFUaAW9wT2olQUABuDn4BvEsaVUIkQSalIityBoCKLFaA2icLKEoCVoK6KoViGKWlsabMihoAiSomyQshJaolTESZQKoh/zNHzD5Zx77rnf1XifJzNdURZlURZlURZlURZlURZlURb/s3/wu8HNmJoXZVEWZXGdLuBPgy9w0uAiPjJ4Cm+bF2VRFmWxBX/jNZzBCVy22jbrRVmURVlswZt42eZux1t4xHpRFmVRFiN9h9etdj8ewNPYa7koi7Ioi5GO45LlnsVz2IGp1aIsyqIsRngHr5r3JF7BDkwxMU6URVmUxQj3WO9LHMXz2G68KIuyKIsRzuKqeT/jKD7GMewzTpRFWZTFCI/jE7xrMMMEM/yIe/EBDtpclEVZlMVIL+EKvsUFg4nBv3gBB7DbalEWZVEWI+3FcVzEr3gC32BicBqH8KnVoizKoixG+hpfWXMQ53DZms/xGR60sSiLsiiLBTO8j+/xHs4bXMM1q13FEZzAHZaLsiiLslhwBY9ZbYaJeTNMsBO32ViURVmUxYLDNjex3sTgB/yE/ZaLsiiLslhwyo25G3tsLMqiLMpiwaP4EGeNtw/34YjBNhuLsiiLsljwBl7Eb/gFx6w5iTN4GHcaPIM9uNU4URZlURZL7MIu3IWHrPkDf+EW3OT6RFmURVlswRRTNybKoizKoizKoizKoizKoizKoizKoizKoizKoizK/gO5nU72pg9JvwAAAABJRU5ErkJg\">"
      ],
      "text/plain": [
       "28×28 Array{Gray{N0f8},2} with eltype Gray{N0f8}:\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " ⋮                                 ⋱                   \n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "load(\"trained_GNN/MNIST_unenforced_v2/test-image-3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f0f22c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...Done\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAW9JREFUaAW9wbHKTnEAB+CHfmXhBgyKxSqj3IFFMVg+N6CI+gYmFqt7sIrxW8xf2b4LUCZZTDaFjuEM7/DKec//1O95MumKsiiLsiiLsiiLsiiLsiiLsiiLsiiLsiiLsiiLsiiLsiiLsjjAd5zhFi7aJsqiLMpiwW2c4hwms9d4bkyURVmUxYJ7OMVk5wWu4oHZJ1zGFcuiLMqiLBY8xTP7fpjdwYnZZFmURVmUxQHe4qGdS7iJdzixTpRFWZTFAY5whC/4hetmd60XZVEWZbHCNTuf8c16URZlURaDPtr3G/F/URZlURaDHtn3Bsf+L8qiLMpiwAf/dmxZlEVZlMWAr/ZNDhNlURZlMeAxntiZHC7KoizKYqMb1omyKIuyGHDfzpl1oizKoiwGvDcuyqIsymKDn9aLsiiLstjggvWiLMqiLFZ6aZsoi7Ioi5VemZ03JsqiLMpi0B9joizKoixWmmwTZVEWZVEWZVEWZX8BMzslNXh5MdIAAAAASUVORK5CYII=",
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAW9JREFUaAW9wbHKTnEAB+CHfmXhBgyKxSqj3IFFMVg+N6CI+gYmFqt7sIrxW8xf2b4LUCZZTDaFjuEM7/DKec//1O95MumKsiiLsiiLsiiLsiiLsiiLsiiLsiiLsiiLsiiLsiiLsiiLsjjAd5zhFi7aJsqiLMpiwW2c4hwms9d4bkyURVmUxYJ7OMVk5wWu4oHZJ1zGFcuiLMqiLBY8xTP7fpjdwYnZZFmURVmUxQHe4qGdS7iJdzixTpRFWZTFAY5whC/4hetmd60XZVEWZbHCNTuf8c16URZlURaDPtr3G/F/URZlURaDHtn3Bsf+L8qiLMpiwAf/dmxZlEVZlMWAr/ZNDhNlURZlMeAxntiZHC7KoizKYqMb1omyKIuyGHDfzpl1oizKoiwGvDcuyqIsymKDn9aLsiiLstjggvWiLMqiLFZ6aZsoi7Ioi5VemZ03JsqiLMpi0B9joizKoixWmmwTZVEWZVEWZVEWZX8BMzslNXh5MdIAAAAASUVORK5C\">"
      ],
      "text/plain": [
       "28×28 reinterpret(reshape, Gray{Float64}, adjoint(::Matrix{Float64})) with eltype Gray{Float64}:\n",
       " Gray{Float64}(9.79743)  Gray{Float64}(9.79742)  …  Gray{Float64}(9.79742)\n",
       " Gray{Float64}(9.79742)  Gray{Float64}(9.79742)     Gray{Float64}(9.79743)\n",
       " Gray{Float64}(9.79746)  Gray{Float64}(9.79743)     Gray{Float64}(9.79742)\n",
       " Gray{Float64}(9.79743)  Gray{Float64}(9.79742)     Gray{Float64}(9.79743)\n",
       " Gray{Float64}(9.79743)  Gray{Float64}(9.68347)     Gray{Float64}(9.79629)\n",
       " Gray{Float64}(9.79746)  Gray{Float64}(9.79742)  …  Gray{Float64}(9.79469)\n",
       " Gray{Float64}(9.79742)  Gray{Float64}(9.79742)     Gray{Float64}(9.75715)\n",
       " Gray{Float64}(9.79739)  Gray{Float64}(9.71251)     Gray{Float64}(9.89672)\n",
       " Gray{Float64}(9.75854)  Gray{Float64}(9.50695)     Gray{Float64}(9.38737)\n",
       " Gray{Float64}(9.79634)  Gray{Float64}(9.59439)     Gray{Float64}(9.17202)\n",
       " ⋮                                               ⋱  \n",
       " Gray{Float64}(9.79745)  Gray{Float64}(9.77948)     Gray{Float64}(9.79752)\n",
       " Gray{Float64}(9.79742)  Gray{Float64}(9.78137)  …  Gray{Float64}(9.78802)\n",
       " Gray{Float64}(9.79743)  Gray{Float64}(9.79738)     Gray{Float64}(9.79746)\n",
       " Gray{Float64}(9.79746)  Gray{Float64}(9.79736)     Gray{Float64}(9.79742)\n",
       " Gray{Float64}(9.79742)  Gray{Float64}(9.79744)     Gray{Float64}(9.79745)\n",
       " Gray{Float64}(9.79744)  Gray{Float64}(9.79744)     Gray{Float64}(9.79744)\n",
       " Gray{Float64}(9.79743)  Gray{Float64}(9.79743)  …  Gray{Float64}(9.79742)\n",
       " Gray{Float64}(9.79745)  Gray{Float64}(9.79742)     Gray{Float64}(9.79742)\n",
       " Gray{Float64}(9.79742)  Gray{Float64}(9.79743)     Gray{Float64}(9.79745)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function subspace_incoherence(F, A)\n",
    "    m, _ = size(A)\n",
    "    Q = Matrix(qr(A).Q)\n",
    "    temp = Q'*F'\n",
    "    return maximum(sqrt.(sum(temp.*temp, dims = 1)))\n",
    "\n",
    "end\n",
    "\n",
    "\n",
    "epoch_to_load = 30\n",
    "# Load the model and test set loader\n",
    "dir = \"trained_GNN/MNIST_unenforced_v2\"\n",
    "encoder_μ, encoder_logvar, W1, W2, W3, Q = load_model_identity(dir, epoch_to_load)\n",
    "\n",
    "colorview(Gray, reshape(Q*relu(W2*relu(W1*randn(20))), 28,28)' )\n",
    "# F = dct(diagm(ones(784)),2);\n",
    "# subspace_incoherence(F,Q)\n",
    "\n",
    "# _,s,_, =svd(W3);\n",
    "# s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1b5ffec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: MNIST.testdata() is deprecated, use `MNIST(split=:test)[:]` instead.\n",
      "└ @ MLDatasets C:\\Users\\Babhru\\.julia\\packages\\MLDatasets\\Xb4Lh\\src\\datasets\\vision\\mnist.jl:195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: MNIST.testdata() is deprecated, use `MNIST(split=:test)[:]` instead.\n",
      "└ @ MLDatasets C:\\Users\\Babhru\\.julia\\packages\\MLDatasets\\Xb4Lh\\src\\datasets\\vision\\mnist.jl:195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.0447461576998724"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pick a image in MNIST to denoise\n",
    "num = 9\n",
    "batch_size = 64\n",
    "shuffle_data = true\n",
    "dataloader = get_test_loader(batch_size, shuffle_data)\n",
    "\n",
    "(x_batch, y_batch) = first(dataloader)\n",
    "i = 1\n",
    "while y_batch[i] != num\n",
    "    i += 1\n",
    "end\n",
    "\n",
    "a= x_batch[:,i];\n",
    "num = 9\n",
    "batch_size = 64\n",
    "shuffle_data = true\n",
    "dataloader = get_test_loader(batch_size, shuffle_data)\n",
    "\n",
    "(x_batch, y_batch) = first(dataloader)\n",
    "i = 1\n",
    "while y_batch[i] != num\n",
    "    i += 1\n",
    "end\n",
    "\n",
    "b= x_batch[:,i];\n",
    "\n",
    "a = randn(784)\n",
    "b = randn(784)\n",
    "\n",
    "BCE_abs(a,a)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
