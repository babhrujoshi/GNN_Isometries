{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87388d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "using BSON: @save\n",
    "using BSON: @load\n",
    "using CSV\n",
    "using DataFrames: DataFrame\n",
    "using Flux\n",
    "using Flux: logitbinarycrossentropy, binarycrossentropy\n",
    "using Flux.Data: DataLoader\n",
    "using Flux: chunk\n",
    "using ImageFiltering\n",
    "using MLDatasets: FashionMNIST\n",
    "using ProgressMeter: Progress, next!\n",
    "using Random\n",
    "using Zygote\n",
    "using MLDatasets\n",
    "using Images\n",
    "using ImageIO\n",
    "using LinearAlgebra\n",
    "using FFTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0efe9194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a reshape layer to use in our decoder\n",
    "struct Reshape\n",
    "    shape\n",
    "end\n",
    "Reshape(args...) = Reshape(args)\n",
    "(r::Reshape)(x) = reshape(x, r.shape)\n",
    "Flux.@functor Reshape ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fbf96e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logit_BCE_shifted (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function get_train_loader(batch_size, shuffle::Bool)\n",
    "    # The MNIST training set is made up of 60k 28 by 28 greyscale images\n",
    "    train_x, train_y = MNIST.traindata(Float32)\n",
    "    train_x = 1 .- reshape(train_x, (784, :))\n",
    "    return DataLoader((train_x, train_y), batchsize=batch_size, shuffle=shuffle, partial=false)\n",
    "end\n",
    "\n",
    "function save_model(encoder_μ, encoder_logvar, W1, W2, W3, Q, save_dir::String, epoch::Int)\n",
    "    print(\"Saving model...\")\n",
    "    let encoder_μ = cpu(encoder_μ), encoder_logvar = cpu(encoder_logvar), W1 = cpu(W1), W2 = cpu(W2), W3 = cpu(W3), Q = cpu(Q)\n",
    "        @save joinpath(save_dir, \"model-$epoch.bson\") encoder_μ encoder_logvar W1 W2 W3 Q\n",
    "    end\n",
    "    println(\"Done\")\n",
    "end\n",
    "\n",
    "function create_vae()\n",
    "    # Define the encoder and decoder networks\n",
    "    encoder_features = Chain(\n",
    "        Dense(784,500, relu),\n",
    "        Dense(500,500, relu)\n",
    "    )\n",
    "    encoder_μ = Chain(encoder_features, Dense(500, 20))\n",
    "    encoder_logvar = Chain(encoder_features, Dense(500, 20))\n",
    "\n",
    "    W1 = randn(500,20)\n",
    "    W2 = randn(500,500)\n",
    "    W3 = randn(784,500)\n",
    "    Q = randn(784,784)\n",
    "\n",
    "    return encoder_μ, encoder_logvar, W1, W2, W3, Q\n",
    "end\n",
    "\n",
    "function sig_shifted_v2(x)\n",
    "    M = 0.375261028309015\n",
    "    X = 0.624697168346519\n",
    "    α = X/0.5\n",
    "    sig(x) = exp(-x^2)*tanh(x)\n",
    "    return @.(sig(α*(x-.5))/(2M)  + 1/2)\n",
    "end\n",
    "\n",
    "function sig_shifted(x)\n",
    "    M = 1.04187855854289\n",
    "    X = 1.01570942991227\n",
    "    α = X/0.25\n",
    "    sig(x) = (exp(-x^2)+.99) * tanh(x)\n",
    "    return @.(sig(α*(x-.5))/(2M)  + 1/2)\n",
    "end\n",
    "\n",
    "function sig_shifted_v3(x)\n",
    "    M = 0.321140015957206\n",
    "    X = 0.58703932739034\n",
    "    α = X/0.5\n",
    "    sig(x) = (exp(-x^2) - .1)*tanh(x)\n",
    "    return @.(sig(α*(x-.5))/(2M)  + 1/2)\n",
    "end\n",
    "\n",
    "function BCE_own(x̂,x)\n",
    "    return sum( @.( -(1-x)*log(1 - (sigmoid(abs(1-x̂)) .- .5) * min((abs(x̂))^1.01, 1) + 1e-5)  - x*( log(1 - (sigmoid(abs(1-x̂)) .- .5)* min((abs(1-x̂))^1.01, 1)  + 1e-5) ) ) )/784\n",
    "end\n",
    "\n",
    "function BCE_own(x̂)\n",
    "    invgaus(x) =  @.(-exp(-(x)^2) +1)\n",
    "    return sum( @.( - log(1 - invgaus( max( abs(.5-x̂) -.5 , .5 ) -.5 ) + 1e-5)  ) )/size(x̂,2)\n",
    "end\n",
    "\n",
    "function  logit_BCE(x̂,x) \n",
    "    return sum(@.(- x * log( sigmoid(x̂) + 1e-5) - (1-x)* log( 1 - sigmoid(x̂) + 1e-5))) / size(x,2)\n",
    "end\n",
    "\n",
    "function  logit_BCE_shifted(x̂,x) \n",
    "    return sum(@.(- x * log( sig_shifted(x̂) + 1e-4) - (1-x)* log( 1 - sig_shifted(x̂) + 1e-4))) / size(x,2)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4fca59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function vae_loss(encoder_μ, encoder_logvar, W1, W2, W3, Q, x, β, λ, F)\n",
    "    batch_size = size(x)[end]\n",
    "    @assert batch_size != 0\n",
    "\n",
    "    # Forward propagate through mean encoder and std encoders\n",
    "    μ = encoder_μ(x)\n",
    "    logvar = encoder_logvar(x)\n",
    "    # Apply reparameterisation trick to sample latent\n",
    "    z = μ + randn(Float32, size(logvar)) .* exp.(0.5f0 * logvar)\n",
    "    # Reconstruct from latent sample\n",
    "\n",
    "    x̂ = Q*sigmoid(W3*relu(W2*relu(W1*z)))\n",
    "\n",
    "    loss_α(F,A) = maximum(sqrt.(sum((F*A).*(F*A), dims = 2))) + 100*norm(A'*A - I(784),2)^2\n",
    "    α = loss_α(F, Q) \n",
    "\n",
    "    logp_x_z = sum(logitbinarycrossentropy.(x̂, x))\n",
    "    # Negative reconstruction loss Ε_q[logp_x_z]\n",
    "    # KL(qᵩ(z|x)||p(z)) where p(z)=N(0,1) and qᵩ(z|x) models the encoder i.e. reverse KL\n",
    "    # The @. macro makes sure that all operates are elementwise\n",
    "    kl_q_p = 0.5f0 * sum(@. (exp(logvar) + μ^2 - logvar - 1f0)) \n",
    "    # Weight decay regularisation term\n",
    "    reg = λ * sum(x->sum(x.^2), Flux.params(encoder_μ, encoder_logvar, W1, W2, W3, Q))\n",
    "    # We want to maximise the evidence lower bound (ELBO)\n",
    "    elbo = - β .* kl_q_p\n",
    "    # So we minimise the sum of the negative ELBO and a weight penalty\n",
    "    return -elbo + reg + logp_x_z + 10000*α\n",
    "end\n",
    "\n",
    "function train(encoder_μ, encoder_logvar, W1, W2, W3, Q, dataloader, num_epochs, λ, β, optimiser, save_dir)\n",
    "    # The training loop for the model\n",
    "    trainable_params = Flux.params(encoder_μ, encoder_logvar, W1, W2, W3, Q)\n",
    "    progress_tracker = Progress(num_epochs, \"Training a epoch done\")\n",
    "    F = dct(diagm(ones(784)),2);\n",
    "\n",
    "    for epoch_num = 21:num_epochs\n",
    "        acc_loss = 0.0\n",
    "        loss = 0\n",
    "        for (x_batch, y_batch) in dataloader\n",
    "            # pullback function returns the result (loss) and a pullback operator (back)\n",
    "            loss, back = pullback(trainable_params) do\n",
    "                vae_loss(encoder_μ, encoder_logvar, W1, W2, W3, Q, x_batch, β, λ, F)\n",
    "            end\n",
    "            # Feed the pullback 1 to obtain the gradients and update then model parameters\n",
    "            gradients = back(1f0)\n",
    "            Flux.Optimise.update!(optimiser, trainable_params, gradients)\n",
    "            if isnan(loss)\n",
    "                break\n",
    "            end\n",
    "            acc_loss += loss\n",
    "        end\n",
    "        next!(progress_tracker; showvalues=[(:loss, loss)])\n",
    "        @assert length(dataloader) > 0\n",
    "        avg_loss = acc_loss / length(dataloader)\n",
    "        metrics = DataFrame(epoch=epoch_num, negative_elbo=avg_loss)\n",
    "        # println(metrics)\n",
    "        CSV.write(joinpath(save_dir, \"metrics.csv\"), metrics, header=(epoch_num==1), append=true)\n",
    "        save_model(encoder_μ, encoder_logvar, W1, W2, W3, Q, save_dir, epoch_num)\n",
    "    end\n",
    "    println(\"Training complete!\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82bc3617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500×500 Matrix{Bool}:\n",
       " 1  0  0  0  0  0  0  0  0  0  0  0  0  …  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  1  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  1  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  1  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  1  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  1  0  0  0  0  0  0  0  …  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  1  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  1  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  1  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  1  0  0  0     0  0  0  0  0  0  0  0  0  0  0  0\n",
       " ⋮              ⋮              ⋮        ⋱        ⋮              ⋮           \n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  1  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  1  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  1  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  1  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  …  0  0  0  0  0  0  0  1  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  1  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  1  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  1  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0     0  0  0  0  0  0  0  0  0  0  0  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "W3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "339ecd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: MNIST.traindata() is deprecated, use `MNIST(split=:train)[:]` instead.\n",
      "└ @ MLDatasets /Users/babhru/.julia/packages/MLDatasets/Xb4Lh/src/datasets/vision/mnist.jl:187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[32mTraining a epoch done   5%|█▌                            |  ETA: 2:23:44\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  35841.038989692985\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done   8%|██▎                           |  ETA: 2:22:07\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  35769.120484857696\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  10%|███                           |  ETA: 2:18:07\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  33844.476506108054\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  12%|███▊                          |  ETA: 2:14:46\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  33731.911666499414\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  15%|████▌                         |  ETA: 2:11:12\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  33868.3133019613\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  18%|█████▎                        |  ETA: 2:07:59\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  33767.16011917154\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  20%|██████                        |  ETA: 2:04:27\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  33645.16422033456\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  22%|██████▊                       |  ETA: 2:00:20\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  32730.472328612057\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  25%|███████▌                      |  ETA: 1:56:21\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  32728.504414784875\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  28%|████████▎                     |  ETA: 1:53:05\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  32757.91350963255\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  30%|█████████                     |  ETA: 1:49:43\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  32790.18816958096\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  32%|█████████▊                    |  ETA: 1:46:08\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  32833.678670754074\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  35%|██████████▌                   |  ETA: 1:42:31\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  32904.73813787953\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  38%|███████████▎                  |  ETA: 1:38:54\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  32765.069042637428\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  40%|████████████                  |  ETA: 1:35:13\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  32443.35943733609\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  42%|████████████▊                 |  ETA: 1:31:16\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  32604.99644805926\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  45%|█████████████▌                |  ETA: 1:27:15\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  32910.1144405929\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  48%|██████████████▎               |  ETA: 1:23:14\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  32743.1282798045\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r\u001b[K\u001b[A\r\u001b[32mTraining a epoch done  50%|███████████████               |  ETA: 1:19:23\u001b[39m\u001b[K\r\n",
      "\u001b[34m  loss:  32692.21877661535\u001b[39m\u001b[K\r\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...Done"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "shuffle_data = true\n",
    "η = 0.001\n",
    "β = 1f0\n",
    "λ = 0.01f0\n",
    "num_epochs = 40\n",
    "\n",
    "save_dir = \"test/trained_GNN/MNIST_sigmoid_ortho\"\n",
    "# Define the model and create our data loader\n",
    "dataloader = get_train_loader(batch_size, shuffle_data)\n",
    "# encoder_μ, encoder_logvar, W1, W2, W3, Q  = create_vae()\n",
    "train(encoder_μ, encoder_logvar, W1, W2, W3, Q, dataloader, num_epochs, λ, β, ADAM(η), save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26330dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "visualise (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function get_test_loader(batch_size, shuffle::Bool)\n",
    "    # The FashionMNIST test set is made up of 10k 28 by 28 greyscale images\n",
    "    test_x, test_y = MNIST.testdata(Float32)\n",
    "    test_x = 1 .- reshape(test_x, (784, :))\n",
    "    return DataLoader((test_x, test_y), batchsize=batch_size, shuffle=shuffle)\n",
    "end\n",
    "\n",
    "function save_to_images(x_batch, save_dir::String, prefix::String, num_images::Int64)\n",
    "    @assert num_images <= size(x_batch)[2]\n",
    "    for i=1:num_images\n",
    "        save(joinpath(save_dir, \"$prefix-$i.png\"), colorview(Gray, reshape(x_batch[:, i], 28,28)' ))\n",
    "    end\n",
    "end\n",
    "\n",
    "function reconstruct_images(encoder_μ, encoder_logvar, W1, W2, W3, Q, x)\n",
    "    # Forward propagate through mean encoder and std encoders\n",
    "    μ = encoder_μ(x)\n",
    "    logvar = encoder_logvar(x)\n",
    "    # Apply reparameterisation trick to sample latent\n",
    "    z = μ + randn(Float32, size(logvar)) .* exp.(0.5f0 * logvar)\n",
    "    # Reconstruct from latent sample\n",
    "    x̂ = Q*sigmoid(W3*relu(W2*relu(W1*z)))\n",
    "    return clamp.(x̂, 0 ,1)\n",
    "end\n",
    "\n",
    "function load_model_identity(load_dir::String, epoch::Int)\n",
    "    print(\"Loading model...\")\n",
    "    @load joinpath(load_dir, \"model-$epoch.bson\") encoder_μ encoder_logvar W1 W2 W3 Q\n",
    "    println(\"Done\")\n",
    "    return encoder_μ, encoder_logvar, W1, W2, W3, Q\n",
    "end\n",
    "\n",
    "function visualise()\n",
    "    # Define some parameters\n",
    "    batch_size = 64\n",
    "    shuffle = true\n",
    "    num_images = 30\n",
    "    epoch_to_load = 40\n",
    "    # Load the model and test set loader\n",
    "    dir = \"test/trained_GNN/MNIST_sigmoid_ortho\"\n",
    "    encoder_μ, encoder_logvar, W1, W2, W3, Q = load_model_identity(dir, epoch_to_load)\n",
    "    dataloader = get_test_loader(batch_size, shuffle)\n",
    "    # Reconstruct and save some images\n",
    "    for (x_batch, y_batch) in dataloader\n",
    "        save_to_images(x_batch, dir, \"test-image\", num_images)\n",
    "        x̂_batch = reconstruct_images(encoder_μ, encoder_logvar, W1, W2, W3, Q, x_batch)\n",
    "        save_to_images(x̂_batch, dir, \"reconstruction\", num_images)\n",
    "        break\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eaf26eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: MNIST.testdata() is deprecated, use `MNIST(split=:test)[:]` instead.\n",
      "└ @ MLDatasets /Users/babhru/.julia/packages/MLDatasets/Xb4Lh/src/datasets/vision/mnist.jl:195\n"
     ]
    }
   ],
   "source": [
    "visualise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "04c4dff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAuFJREFUaAW9wWtv0wUYB9DT9rfu0tGVyZBNRcQoQX1j/P7fwZioRIJBp4TLNrsbW2+rL/pq4V8umjznZK5WFItiUSyKRbEoFsWiWBSLYlEsikWxKBbF4gNMcIgDHOIYLWxjB9vYRttyUSyKRbF4D6d4hn08wWM8xylWsIf7uIsv8TkGmkWxKBbF4h2O8ASP8At+xmM8wwg97OAuvsM5JvgKW94UxaJYFIu3GOIpHuFH/ITfsY+JhRHOMUEHW9jCAJvouC6KRbEoFktMcIC/8RS/YR9DtLFhoYPgEkO8whHOMEXHdVEsikWxWGKEcwzxEkNM0cen6OMKY5zgCsHcQgfxpigWxaJYLDHHGGc4wRhruINdbOAMB5hhgh566KGHjjdFsSgWxWKJK4xwglN0sIvPcAsjHOMSl2hhDQMMsKpZFItiUSyWmOIUx5igix66GOI5/sQRLnELm9jGJqJZFItiUSyWGOEMI7TRtXCAffyBl5ijg9tYRQ8dtDWLYlEsisUSF5hgihbauMJz/IpT17UQTDHDTLMoFsWiWCwxxhxdrKGFEY5x6rpN3MAq5phiplkUi2JRLBpMMEMHGxjgEidYxwBDC2vYxg20MUUbHc2iWBSLYtFgjDm66GOMS6xihileYYQ2emhjjjY66GoWxaJYFIsGI1xhBRu4gTZauIlzTHFoYYwJWljFKlY0i2JRLIrFEjOMMMYFzvAa57jAOS5whXWsoo8++ljTLIpFsSgWDdqYY4IzHOAIQxziBY4wwQb62MMePsYWVjSLYlEsikWDDayhixlO8Bde4gBDCy3cxD08wBf4BLcsF8WiWBSLBl3cxj84xAusYIwZugj28A1+wLf4GrveLopFsSgWS+xYaKGDdQwwtNDHPTzEQzzArneLYlEsisVb7OAj3Mf3OMBrzLGBm9jBHax7P1EsikWxeIc2drFr4Qpt/10Ui2JRLD5Q2/8TxaJYFItiUSyKRbF/Aa3Nqvl3XlxMAAAAAElFTkSuQmCC",
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAuFJREFUaAW9wWtv0wUYB9DT9rfu0tGVyZBNRcQoQX1j/P7fwZioRIJBp4TLNrsbW2+rL/pq4V8umjznZK5WFItiUSyKRbEoFsWiWBSLYlEsikWxKBbF4gNMcIgDHOIYLWxjB9vYRttyUSyKRbF4D6d4hn08wWM8xylWsIf7uIsv8TkGmkWxKBbF4h2O8ASP8At+xmM8wwg97OAuvsM5JvgKW94UxaJYFIu3GOIpHuFH/ITfsY+JhRHOMUEHW9jCAJvouC6KRbEoFktMcIC/8RS/YR9DtLFhoYPgEkO8whHOMEXHdVEsikWxWGKEcwzxEkNM0cen6OMKY5zgCsHcQgfxpigWxaJYLDHHGGc4wRhruINdbOAMB5hhgh566KGHjjdFsSgWxWKJK4xwglN0sIvPcAsjHOMSl2hhDQMMsKpZFItiUSyWmOIUx5igix66GOI5/sQRLnELm9jGJqJZFItiUSyWGOEMI7TRtXCAffyBl5ijg9tYRQ8dtDWLYlEsisUSF5hgihbauMJz/IpT17UQTDHDTLMoFsWiWCwxxhxdrKGFEY5x6rpN3MAq5phiplkUi2JRLBpMMEMHGxjgEidYxwBDC2vYxg20MUUbHc2iWBSLYtFgjDm66GOMS6xihileYYQ2emhjjjY66GoWxaJYFIsGI1xhBRu4gTZauIlzTHFoYYwJWljFKlY0i2JRLIrFEjOMMMYFzvAa57jAOS5whXWsoo8++ljTLIpFsSgWDdqYY4IzHOAIQxziBY4wwQb62MMePsYWVjSLYlEsikWDDayhixlO8Bde4gBDCy3cxD08wBf4BLcsF8WiWBSLBl3cxj84xAusYIwZugj28A1+wLf4GrveLopFsSgWS+xYaKGDdQwwtNDHPTzEQzzArneLYlEsisVb7OAj3Mf3OMBrzLGBm9jBHax7P1EsikWxeIc2drFr4Qpt/10Ui2JRLD5Q2/8TxaJYFItiUSyKRbF/Aa3Nqvl3XlxMAAAAAElFTkSuQmCC\">"
      ],
      "text/plain": [
       "28×28 Array{Gray{N0f8},2} with eltype Gray{N0f8}:\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " ⋮                                 ⋱                   \n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "load(\"test/trained_GNN/MNIST_sigmoid_ortho/reconstruction-7.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ecd198a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAiFJREFUaAW9wT2I1nUAB/DPI1+KkDKJhrqGwMAowQxqiDbXoiCXa4ogCKFBSKe6pXJpP45eoKElCOxlEmooaIugIoegINxCehkOTaJr+A0Ph9zzfx4Pvp9PdnRFWZRFWZRFWZRFWZRFWZRFWZRFWZRFWZRFWZRFWSxhG8Gtht9wBmt4GS/iGh7DGcP9OOhGURZlURYTruEFXMbjOILf8RnuxSZmhp/wAXawgVN42G5RFmVRFhO+xAXDd3gLh3Acz2ATM2zjP8NVvI1NvIenzUVZlEVZTPjW3FGcNZwzbBgu4R/DLzhiuNtuURZlURYrOGZvD5k7YW9RFmVRFhO+xo7hSfsXZVEWZTFhhpnhWfsXZVEWZbHA6/jK3Bqu4grexKf4AXfiFsuJsiiLsljgG+yY+xmv4gtcN9yDD7FuOVEWZVEWK3gCf5k7hh9xGn/itGlRFmVRFgu8g0exbfgDM7yELcNHeB5ncRQnLRZlURZlscADWMf7hjuwiVPmnsIj+B7ncdJiURZlURYTzmPN8AoO2+0gDllelEVZlMWEu7Bhb5dxyfKiLMqiLPbpXVyxvCiLsiiLffgEb+CAYce0KIuyKIsV/I3ruB1b2MABzAwz06IsyqIsVnABr+E4LrrRbaZFWZRFWazgOD7Hx7hotwexZVqURVmUxQpOGH41dxjrOIf7TIuyKIuyuAnP4V83J8qiLMqiLMqiLMqiLMqiLMr+B5ISTKYkNNqLAAAAAElFTkSuQmCC",
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAiFJREFUaAW9wT2I1nUAB/DPI1+KkDKJhrqGwMAowQxqiDbXoiCXa4ogCKFBSKe6pXJpP45eoKElCOxlEmooaIugIoegINxCehkOTaJr+A0Ph9zzfx4Pvp9PdnRFWZRFWZRFWZRFWZRFWZRFWZRFWZRFWZRFWZRFWSxhG8Gtht9wBmt4GS/iGh7DGcP9OOhGURZlURYTruEFXMbjOILf8RnuxSZmhp/wAXawgVN42G5RFmVRFhO+xAXDd3gLh3Acz2ATM2zjP8NVvI1NvIenzUVZlEVZTPjW3FGcNZwzbBgu4R/DLzhiuNtuURZlURYrOGZvD5k7YW9RFmVRFhO+xo7hSfsXZVEWZTFhhpnhWfsXZVEWZbHA6/jK3Bqu4grexKf4AXfiFsuJsiiLsljgG+yY+xmv4gtcN9yDD7FuOVEWZVEWK3gCf5k7hh9xGn/itGlRFmVRFgu8g0exbfgDM7yELcNHeB5ncRQnLRZlURZlscADWMf7hjuwiVPmnsIj+B7ncdJiURZlURYTzmPN8AoO2+0gDllelEVZlMWEu7Bhb5dxyfKiLMqiLPbpXVyxvCiLsiiLffgEb+CAYce0KIuyKIsV/I3ruB1b2MABzAwz06IsyqIsVnABr+E4LrrRbaZFWZRFWazgOD7Hx7hotwexZVqURVmUxQpOGH41dxjrOIf7TIuyKIuyuAnP4V83J8qiLMqiLMqiLMqiLMqiLMr+B5ISTKYkNNqLAAAAAElFTkSuQmCC\">"
      ],
      "text/plain": [
       "28×28 Array{Gray{N0f8},2} with eltype Gray{N0f8}:\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " ⋮                                 ⋱                   \n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)  …  Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)\n",
       " Gray{N0f8}(1.0)  Gray{N0f8}(1.0)     Gray{N0f8}(1.0)  Gray{N0f8}(1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "load(\"trained_GNN/MNIST_sigmoid/test-image-7.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0f22c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...Done\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/html": [
       "<img src=\"data:image/png;base64,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\">"
      ],
      "text/plain": [
       "28×28 reinterpret(reshape, Gray{Float64}, adjoint(::Matrix{Float64})) with eltype Gray{Float64}:\n",
       " Gray{Float64}(0.399005)    …  Gray{Float64}(0.261003)\n",
       " Gray{Float64}(0.554511)       Gray{Float64}(0.289194)\n",
       " Gray{Float64}(-0.0256272)     Gray{Float64}(0.254961)\n",
       " Gray{Float64}(0.247227)       Gray{Float64}(0.741209)\n",
       " Gray{Float64}(1.59835)        Gray{Float64}(1.41188)\n",
       " Gray{Float64}(0.534084)    …  Gray{Float64}(0.822661)\n",
       " Gray{Float64}(1.31037)        Gray{Float64}(1.23264)\n",
       " Gray{Float64}(0.556237)       Gray{Float64}(-0.152939)\n",
       " Gray{Float64}(0.420813)       Gray{Float64}(0.655861)\n",
       " Gray{Float64}(0.63305)        Gray{Float64}(0.874424)\n",
       " ⋮                          ⋱  \n",
       " Gray{Float64}(0.329645)       Gray{Float64}(0.89592)\n",
       " Gray{Float64}(0.125635)    …  Gray{Float64}(-0.152858)\n",
       " Gray{Float64}(0.541889)       Gray{Float64}(0.53811)\n",
       " Gray{Float64}(0.564071)       Gray{Float64}(0.797092)\n",
       " Gray{Float64}(1.50444)        Gray{Float64}(0.33014)\n",
       " Gray{Float64}(-0.0346199)     Gray{Float64}(-0.516335)\n",
       " Gray{Float64}(1.43448)     …  Gray{Float64}(1.22612)\n",
       " Gray{Float64}(1.15377)        Gray{Float64}(0.57228)\n",
       " Gray{Float64}(0.169205)       Gray{Float64}(0.345209)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function subspace_incoherence(F, A)\n",
    "    m, _ = size(A)\n",
    "    Q = Matrix(qr(A).Q)\n",
    "    temp = Q'*F'\n",
    "    return maximum(sqrt.(sum(temp.*temp, dims = 1)))\n",
    "\n",
    "end\n",
    "\n",
    "\n",
    "epoch_to_load = 20\n",
    "# Load the model and test set loader\n",
    "dir = \"test/trained_GNN/MNIST_sigmoid_ortho\"\n",
    "encoder_μ, encoder_logvar, W1, W2, W3, Q = load_model_identity(dir, epoch_to_load)\n",
    "\n",
    "colorview(Gray, reshape( Q*sigmoid(W3*relu(W2*relu(W1*randn(20)))) , 28,28)' )\n",
    "# F = dct(diagm(ones(784)),2);\n",
    "# subspace_incoherence(F,Q)\n",
    "\n",
    "# _,s,_, =svd(W3);\n",
    "# s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc915d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784×784 Matrix{Float64}:\n",
       " -0.0143417     0.0299113    0.00799201   …  -9.14608e-5  -0.0141516\n",
       "  0.0228648     0.0355191   -0.0126749       -0.022978    -0.0356237\n",
       " -0.00102533    0.0283498   -0.0298063       -0.00450832   0.0161471\n",
       " -0.0122688    -0.0123263    0.0214618        0.00992346   0.0492092\n",
       "  0.048088      0.00803735  -0.0531604        0.00945767   0.0104223\n",
       "  0.00757494    0.00871871  -0.0272488    …   0.0256457   -0.013405\n",
       " -0.0259408     0.0367648   -0.0766937       -0.00668258   0.018294\n",
       " -0.0219253    -0.0015512   -0.00252023       0.0353524    0.009163\n",
       "  0.00559264   -0.0088321   -0.020055         0.00211783   0.0119465\n",
       "  0.000630044  -0.00458154   0.0101728       -0.0148414   -0.0080099\n",
       "  ⋮                                       ⋱               \n",
       " -0.0178676     0.033772     0.0222209    …  -0.0104565   -0.0120851\n",
       "  0.0410387     0.0130235    0.00876929       0.0236314    0.0340738\n",
       " -0.0244286     0.104918     0.000499203     -0.042705     0.00116394\n",
       " -0.0295796    -0.0178645    0.0956214       -0.00314449   0.0213357\n",
       "  0.00307866   -0.0166582   -0.00940956      -0.0211846   -0.0188125\n",
       " -0.0113174     0.00508236  -0.0053696    …  -0.0116857   -0.00793081\n",
       "  0.00150982    0.00618264   0.016858        -0.0163787   -0.00264812\n",
       " -0.0126654     0.019786     0.00982577       0.010084     0.0313998\n",
       " -0.0337486     0.0356262    0.0336817        0.0155035   -0.0140477"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b5ffec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999546021312976"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sigmoid(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8a1b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
